import asyncio
import logging
import os
import json
import aiohttp
from dotenv import load_dotenv
from typing import Union, Literal
from dataclasses import dataclass

from livekit import agents
from livekit.agents import (
    AgentSession,
    Agent,
    JobContext,
    tts,
    llm,
)
from livekit.agents.llm import (
    LLMStream,
    ChatContext,
    ChatChunk,
    ChoiceDelta,
    CompletionUsage,
)
from livekit.agents.llm.chat_context import ChatRole
from livekit.agents.tts import SynthesizeStream
from livekit.plugins import silero

# Charger les variables d'environnement du fichier .env
load_dotenv()

# Configuration du logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


# --- Plugins Personnalis√©s (Compatible livekit-agents v1.1.5) ---

@dataclass
class ConnectionOptions:
    timeout: float = 30.0

class MistralLLMStream(LLMStream):
    def __init__(
        self,
        llm: "MistralLLM",
        chat_ctx: ChatContext,
        conn_options: ConnectionOptions,
        api_key: str,
        model: str,
        base_url: str,
    ):
        super().__init__(llm=llm, chat_ctx=chat_ctx, tools=[], conn_options=conn_options)
        self._api_key = api_key
        self._model = model
        self._base_url = base_url
        self._conn_options = conn_options

    async def _run(self) -> None:
        messages = self._prepare_messages()
        headers = {
            "Authorization": f"Bearer {self._api_key}",
            "Content-Type": "application/json",
        }
        payload = {"model": self._model, "messages": messages, "stream": True}
        
        logger.debug(f"üîµ [MISTRAL] Envoi √† Mistral - Base URL: {self._base_url}, Payload: {payload}, Headers: {{'Authorization': 'Bearer ...'}}")

        try:
            timeout = aiohttp.ClientTimeout(total=self._conn_options.timeout)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.post(
                    self._base_url, json=payload, headers=headers
                ) as response:
                    response.raise_for_status()
                    async for line in response.content:
                        line = line.decode("utf-8").strip()
                        if not line or not line.startswith("data: "):
                            continue
                        if line == "data: [DONE]":
                            break
                        try:
                            json_data = line[6:]
                            data = json.loads(json_data)
                            chunk = self._create_chat_chunk(data)
                            self._event_ch.send_nowait(chunk)
                        except json.JSONDecodeError:
                            logger.warning(f"Failed to parse JSON: {json_data}")
        except aiohttp.ClientResponseError as e:
            if e.status == 401:
                logger.error(f"‚ùå [MISTRAL] Cl√© API Mistral invalide ou manquante (401 Unauthorized)")
                # Envoyer une r√©ponse de fallback au lieu de faire planter l'agent
                fallback_chunk = self._create_fallback_chunk()
                self._event_ch.send_nowait(fallback_chunk)
            else:
                logger.error(f"‚ùå [MISTRAL] Erreur HTTP {e.status}: {e}")
                fallback_chunk = self._create_fallback_chunk()
                self._event_ch.send_nowait(fallback_chunk)
        except Exception as e:
            logger.error(f"‚ùå [MISTRAL] Erreur inattendue: {e}")
            # Envoyer une r√©ponse de fallback au lieu de faire planter l'agent
            fallback_chunk = self._create_fallback_chunk()
            self._event_ch.send_nowait(fallback_chunk)

    def _prepare_messages(self) -> list[dict]:
        """Pr√©pare les messages pour l'API Mistral - CORRIG√â pour livekit-agents v1.1.5"""
        
        try:
            # CORRECTION: Dans livekit-agents v1.1.5, utiliser chat_ctx.items au lieu de chat_ctx.messages
            messages = []
            
            # Acc√©der aux messages via l'attribut 'items' (nouvelle API v1.1.5)
            if hasattr(self._chat_ctx, 'items') and self._chat_ctx.items:
                logger.info(f"‚úÖ [CHATCONTEXT] Trouv√© {len(self._chat_ctx.items)} messages via 'items'")
                
                for msg in self._chat_ctx.items:
                    # Convertir le ChatMessage en format Mistral
                    if hasattr(msg, 'role') and hasattr(msg, 'content'):
                        # G√©rer le contenu qui peut √™tre une liste ou une cha√Æne
                        content = msg.content
                        if isinstance(content, list):
                            content = ' '.join(str(item) for item in content)
                        elif not isinstance(content, str):
                            content = str(content)
                        
                        # Filtrer les messages avec contenu vide pour √©viter les erreurs 400 avec l'API
                        if content.strip():
                            messages.append({
                                "role": msg.role,
                                "content": content
                            })
                            logger.debug(f"[CHATCONTEXT] Message –¥–æ–±–∞–≤–ª–µ–Ω–æ: {msg.role} -> {content[:50]}...")
                        else:
                            logger.warning(f"‚ö†Ô∏è [CHATCONTEXT] Message ignor√© avec contenu vide pour le r√¥le {msg.role}.")
            else:
                logger.warning("‚ö†Ô∏è [CHATCONTEXT] Aucun message trouv√© dans chat_ctx.items")
                # Fallback: cr√©er un message syst√®me par d√©faut si aucun message valide n'est trouv√©
                logger.info("‚ÑπÔ∏è [CHATCONTEXT] Reversion au message syst√®me par d√©faut.")
                messages.append({
                    "role": "system",
                    "content": "You are a helpful voice AI assistant for eloquence coaching."
                })
            
            logger.info(f"‚úÖ [CHATCONTEXT] {len(messages)} messages pr√©par√©s pour Mistral API")
            return messages
            
        except Exception as e:
            logger.error(f"‚ùå [CHATCONTEXT] Erreur lors de la pr√©paration des messages: {e}")
            # Fallback en cas d'erreur
            return [{
                "role": "system",
                "content": "You are a helpful voice AI assistant for eloquence coaching."
            }]

    def _create_chat_chunk(self, data: dict) -> ChatChunk:
        content = ""
        if 'choices' in data and len(data['choices']) > 0:
            choice = data['choices'][0]
            if 'delta' in choice and 'content' in choice['delta']:
                content = choice['delta']['content'] or ""
        
        delta = ChoiceDelta(role="assistant", content=content)
        return ChatChunk(delta=delta, id=data.get('id', ''))

    def _create_fallback_chunk(self) -> ChatChunk:
        """Create a fallback ChatChunk when API calls fail."""
        fallback_message = "Je rencontre des difficult√©s techniques avec le service LLM. Pouvez-vous r√©p√©ter votre question ?"
        delta = ChoiceDelta(role="assistant", content=fallback_message)
        return ChatChunk(delta=delta, id="fallback")


class MistralLLM(llm.LLM):
    def __init__(self):
        super().__init__()
        self._api_key = os.environ.get("MISTRAL_API_KEY")
        self._model = os.getenv("MISTRAL_MODEL", "mistral-small-latest")
        self._base_url = os.getenv("MISTRAL_BASE_URL", "https://api.mistral.ai/v1/chat/completions")

    def chat(
        self,
        *,
        chat_ctx: ChatContext,
        conn_options: ConnectionOptions | None = None,
        **kwargs,
    ) -> LLMStream:
        conn_options = conn_options or ConnectionOptions()
        return MistralLLMStream(
            llm=self,
            chat_ctx=chat_ctx,
            conn_options=conn_options,
            api_key=self._api_key,
            model=self._model,
            base_url=self._base_url,
        )


class LocalOpenAITTSStream(SynthesizeStream):
    def __init__(
        self,
        tts: "LocalOpenAITTS",
        text: str,
        endpoint: str,
        conn_options: ConnectionOptions,
        api_key: str,
    ):
        super().__init__(tts=tts, conn_options=conn_options)
        self._text = text
        self._endpoint = endpoint
        self._conn_options = conn_options
        self._api_key = api_key

    async def _run(self, *args, **kwargs) -> None: # Changement pour le d√©bogage si output_emitter est pass√© diff√©remment
        """CORRIG√â: Signature mise √† jour pour livekit-agents v1.1.5 avec output_emitter et support API OpenAI externe"""
        output_emitter = kwargs.get('output_emitter') if 'output_emitter' in kwargs else (args[0] if args else None)
        if not output_emitter:
            logger.error("‚ùå [TTS] output_emitter n'a pas √©t√© trouv√© dans _run")
            raise ValueError("output_emitter est requis pour SynthesizeStream")

        payload = {"model": "tts-1", "input": self._text, "voice": "alloy", "response_format": "pcm"} # Correction: retirer le taux d'√©chantillonnage
        headers = {"Authorization": f"Bearer {self._api_key}"}
        
        logger.debug(f"üîµ [TTS] Envoi √† OpenAI TTS - Endpoint: {self._endpoint}, Payload: {payload}, Headers: {{'Authorization': 'Bearer ...'}}")

        try:
            timeout = aiohttp.ClientTimeout(total=self._conn_options.timeout)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.post(self._endpoint, json=payload, headers=headers) as response:
                    response.raise_for_status()
                    audio_data = await response.read()
                    chunk_size = 4096
                    for i in range(0, len(audio_data), chunk_size):
                        # CORRIG√â: Utiliser output_emitter au lieu de self._event_ch
                        await output_emitter(
                            tts.SynthesizeStreamData(data=audio_data[i : i + chunk_size])
                        )
                        await asyncio.sleep(0.01)
                    logger.info(f"‚úÖ [TTS] Audio g√©n√©r√© avec succ√®s: {len(audio_data)} bytes")
        except Exception as e:
            logger.error(f"‚ùå [TTS] Erreur dans LocalOpenAITTSStream._run: {e}")
            raise


class LocalOpenAITTS(tts.TTS):
    def __init__(self):
        super().__init__(
            capabilities=tts.TTSCapabilities(streaming=True),
            sample_rate=16000,
            num_channels=1
        )
        self._endpoint = "https://api.openai.com/v1/audio/speech"  # Utilisation de l'API OpenAI externe, URL directe
        self._api_key = os.getenv("OPENAI_API_KEY")  # R√©cup√©ration de la cl√© API

    def synthesize(
        self, *, text: str, conn_options: ConnectionOptions | None = None
    ) -> SynthesizeStream:
        conn_options = conn_options or ConnectionOptions()
        return LocalOpenAITTSStream(
            tts=self, text=text, endpoint=self._endpoint, conn_options=conn_options, api_key=self._api_key
        )

    def stream(self, *, conn_options: ConnectionOptions | None = None) -> SynthesizeStream:
        """M√©thode stream() requise pour le streaming TTS dans livekit-agents v1.1.5"""
        conn_options = conn_options or ConnectionOptions()
        # Pour le streaming, on retourne un stream vide qui sera aliment√© par synthesize()
        return LocalOpenAITTSStream(
            tts=self, text="", endpoint=self._endpoint, conn_options=conn_options, api_key=self._api_key
        )


# --- Agent ---

# D√©finition de notre agent personnalis√©
class EloquenceCoach(Agent):
    def __init__(self) -> None:
        super().__init__(
            instructions="You are a helpful voice AI assistant for eloquence coaching. Be encouraging and provide clear feedback."
        )

    # Cette m√©thode est appel√©e lorsque l'agent doit r√©pondre.
    # Pour l'instant, nous laissons AgentSession la g√©rer implicitement.

async def entrypoint(ctx: agents.JobContext):
    """
    Point d'entr√©e principal pour le worker de l'agent, utilisant le framework moderne v1.0.
    """
    logger.info("üöÄ [ENTRYPOINT] D√©marrage du job de l'agent (v1.0)")

    # Utilisation de nos plugins personnalis√©s
    session = AgentSession(
        llm=MistralLLM(),
        tts=LocalOpenAITTS(),
        vad=silero.VAD.load(),
    )

    # L'agent personnalis√© qui d√©finit le comportement
    agent = EloquenceCoach()

    # D√©marrer la session. AgentSession g√®re automatiquement la cr√©ation
    # et la publication des pistes audio.
    logger.info("üîß [SESSION] D√©marrage de la session Agent...")
    await session.start(
        room=ctx.room,
        agent=agent,
    )
    logger.info("‚úÖ [SESSION] Session Agent d√©marr√©e.")

    # Connexion √† la room
    await ctx.connect()
    logger.info(f"‚úÖ [ROOM] Agent connect√© √† la room: {ctx.room.name}")

    # Envoyer un message de bienvenue pour indiquer que l'agent est pr√™t
    logger.info("üéôÔ∏è [WELCOME] Envoi du message de bienvenue...")
    await session.generate_reply(
        instructions="Bonjour ! Je suis votre coach d'√©loquence IA. Je suis maintenant connect√© et pr√™t √† vous aider. Parlez-moi pour commencer notre session."
    )
    logger.info("‚úÖ [WELCOME] Message de bienvenue envoy√©.")

    # Boucle principale pour les t√¢ches p√©riodiques (si n√©cessaire)
    # Par exemple, un test audio toutes les 30 secondes.
    test_counter = 0

    # Surveiller les √©v√©nements de transcription (STT) et les messages du chat
    async for e in session.events():
        if isinstance(e, agents.Agent.AgentSpeechEvent):
            if e.type == agents.Agent.AgentSpeechEventTypes.STARTED:
                logger.info("üîä [SPEECH] D√©tection de parole STARTED")
            elif e.type == agents.Agent.AgentSpeechEventTypes.FINISHED:
                logger.info("üîä [SPEECH] D√©tection de parole FINISHED")
        elif isinstance(e, agents.Agent.AgentUserSpeechEvent):
            logger.info(f"üó£Ô∏è [USER_SPEECH] Transcription utilisateur: {e.text}")
            if e.text:
                logger.info(f"‚úÖ [STT] Texte transcrit non vide: {e.text}")
            else:
                logger.warning(f"‚ö†Ô∏è [STT] Texte transcrit vide re√ßu.")
        elif isinstance(e, agents.Agent.AgentChatMessageEvent):
            logger.info(f"üí¨ [CHAT] Message de chat re√ßu: {e.message.body}")
        
    # La boucle infinie de test audio sera ex√©cut√©e en parall√®le avec session.events() si n√©cessaire,
    # ou on peut la commenter temporairement pour se concentrer sur le flux principal.
    # Pour l'instant, je la laisse comment√©e puisque l'interaction utilisateur pose probl√®me.
    # while True:
    #     await asyncio.sleep(30)
    #     test_counter += 1
    #
    #     try:
    #         if hasattr(session, '_closed') and session._closed:
    #             logger.error(f"‚ùå [SESSION] Session ferm√©e d√©tect√©e (test #{test_counter})")
    #             break
    #
    #         if hasattr(session, 'is_running') and not session.is_running():
    #             logger.error(f"‚ùå [SESSION] Session n'est plus en cours d'ex√©cution (test #{test_counter})")
    #             break
    #
    #         logger.info(f"üîÑ [LOOP] Test audio p√©riodique #{test_counter}")
    #         logger.info(f"‚úÖ [SESSION] Session √©tat: active")
    #
    #         await session.generate_reply(
    #             instructions=f"Test audio num√©ro {test_counter}. Je suis toujours actif."
    #         )
    #         logger.info(f"‚úÖ [LOOP] Test audio #{test_counter} envoy√© avec succ√®s")
    #
    #     except RuntimeError as e:
    #         if "AgentSession isn't running" in str(e):
    #             logger.error(f"‚ùå [SESSION] Session ferm√©e pendant le test #{test_counter}: {e}")
    #             logger.info("üîÑ [SESSION] Tentative de red√©marrage de la session...")
    #
    #             try:
    #                 await session.start(room=ctx.room, agent=agent)
    #                 logger.info("‚úÖ [SESSION] Session red√©marr√©e avec succ√®s")
    #             except Exception as restart_e:
    #                 logger.error(f"‚ùå [SESSION] √âchec du red√©marrage: {restart_e}")
    #                 break
    #         else:
    #             logger.error(f"‚ùå [LOOP] Erreur RuntimeError inattendue: {e}")
    #             break
    #
    #     except Exception as e:
    #         logger.error(f"‚ùå [LOOP] Erreur inattendue dans la boucle p√©riodique: {e}")
    #         logger.error(f"Type d'erreur: {type(e).__name__}")
    #         continue

# Point d'entr√©e principal du script
if __name__ == "__main__":
    print("[MAIN] Demarrage du worker de l'agent Eloquence (v1.0)...", flush=True)
    
    # Utilisation de la m√©thode recommand√©e pour lancer l'agent.
    # cli.run_app g√®re la boucle asyncio, la cr√©ation du worker, et les signaux d'arr√™t.
    agents.cli.run_app(agents.WorkerOptions(entrypoint_fnc=entrypoint))