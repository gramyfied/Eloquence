import asyncio
import json
import logging
import os
import time
import numpy as np
from dataclasses import dataclass
from typing import Any, AsyncIterator, Callable, Dict, List, Optional

from livekit import rtc
from livekit import agents
from livekit.agents import JobContext, llm, stt, tts, Agent, AgentSession
from datetime import datetime
import aiohttp
import tempfile
import wave
import base64
from scipy.signal import resample
import uuid

# Configuration du logging
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

@dataclass
class AudioDiagnosticData:
    """Donn√©es de diagnostic audio"""
    timestamp: float
    frame_count: int
    sample_rate: int
    num_channels: int
    data_length: int
    energy: float
    max_amplitude: float
    min_amplitude: float
    rms: float
    zero_crossing_rate: float
    is_silent: bool
    raw_data_sample: List[float]  # Premiers 10 √©chantillons pour debug

class AudioDiagnosticAgent:
    """Agent de diagnostic audio avanc√© pour identifier les probl√®mes d'audio silencieux"""
    
    def __init__(self):
        self.diagnostic_data: List[AudioDiagnosticData] = []
        self.frame_counter = 0
        self.total_frames_received = 0
        self.silent_frames_count = 0
        self.non_silent_frames_count = 0
        self.start_time = time.time()
        
    async def entrypoint(self, ctx: JobContext):
        """Point d'entr√©e agent avec diagnostic audio complet"""
        
        logger.info("üîç [DIAGNOSTIC] === D√âMARRAGE AGENT DIAGNOSTIC AUDIO ===")
        
        try:
            # √âTAPE 1 : Configuration audio source avec diagnostic
            logger.info("üîß [DIAGNOSTIC] Configuration AudioSource avec monitoring...")
            audio_source = rtc.AudioSource(sample_rate=24000, num_channels=1)
            logger.info("‚úÖ [DIAGNOSTIC] AudioSource configur√©e : 24kHz, mono")
            
            # √âTAPE 2 : Cr√©er track audio avec diagnostic
            track_name = f"diagnostic-agent-{uuid.uuid4().hex[:8]}"
            audio_track = rtc.LocalAudioTrack.create_audio_track(track_name, audio_source)
            logger.info(f"‚úÖ [DIAGNOSTIC] LocalAudioTrack cr√©√©e : {track_name}")
            
            # √âTAPE 3 : Publier track avec options de diagnostic
            publication = await ctx.room.local_participant.publish_track(
                audio_track,
                rtc.TrackPublishOptions(
                    name="diagnostic-agent-audio",
                    source=rtc.TrackSource.SOURCE_MICROPHONE,
                    stereo=False,
                    dtx=False,  # D√©sactiver DTX pour diagnostic
                    red=True,
                    simulcast=False
                )
            )
            logger.info(f"‚úÖ [DIAGNOSTIC] Track publi√©e - SID: {publication.sid}")
            
            # √âTAPE 4 : Configurer callbacks de diagnostic
            await self.setup_diagnostic_callbacks(ctx, audio_source)
            
            # √âTAPE 5 : D√©marrer monitoring continu
            await self.start_continuous_monitoring(ctx, audio_source)
            
        except Exception as e:
            logger.error(f"‚ùå [DIAGNOSTIC] Erreur critique agent: {e}")
            raise
    
    async def setup_diagnostic_callbacks(self, ctx: JobContext, audio_source: rtc.AudioSource):
        """Configure les callbacks de diagnostic audio"""
        
        logger.info("üîß [DIAGNOSTIC] Configuration callbacks de diagnostic...")
        
        @ctx.room.on("track_subscribed")
        def on_track_subscribed(track, publication, participant):
            if track.kind == rtc.TrackKind.KIND_AUDIO:
                logger.info(f"üé§ [DIAGNOSTIC] Track audio souscrite: {track.sid}")
                logger.info(f"üé§ [DIAGNOSTIC] Participant: {participant.identity}")
                logger.info(f"üé§ [DIAGNOSTIC] Publication: {publication.sid}")
                
                # D√©marrer le diagnostic de cette track
                asyncio.create_task(self.diagnose_audio_track(track, audio_source))
        
        @ctx.room.on("participant_connected")
        def on_participant_connected(participant):
            logger.info(f"üë§ [DIAGNOSTIC] Participant connect√©: {participant.identity}")
        
        @ctx.room.on("participant_disconnected")
        def on_participant_disconnected(participant):
            logger.info(f"üë§ [DIAGNOSTIC] Participant d√©connect√©: {participant.identity}")
        
        logger.info("‚úÖ [DIAGNOSTIC] Callbacks configur√©s")
    
    async def diagnose_audio_track(self, user_track, agent_audio_source):
        """Diagnostic complet d'une track audio utilisateur"""
        
        logger.info("üîç [DIAGNOSTIC] === D√âMARRAGE DIAGNOSTIC TRACK AUDIO ===")
        
        try:
            # Cr√©er un stream audio pour analyser les frames
            audio_stream = rtc.AudioStream(user_track)
            
            # Buffer pour accumuler les frames
            audio_buffer = []
            frame_count = 0
            
            async for audio_frame_event in audio_stream:
                frame_count += 1
                self.total_frames_received += 1
                
                # Extraire les donn√©es audio
                frame = audio_frame_event.frame
                
                # Diagnostic d√©taill√© de la frame
                diagnostic = await self.analyze_audio_frame(frame, frame_count)
                self.diagnostic_data.append(diagnostic)
                
                # Log diagnostic toutes les 10 frames
                if frame_count % 10 == 0:
                    await self.log_diagnostic_summary(frame_count)
                
                # Accumuler dans le buffer
                audio_buffer.append(frame)
                
                # Traiter le buffer toutes les 100 frames (environ 1 seconde √† 24kHz)
                if len(audio_buffer) >= 100:
                    await self.process_audio_buffer(audio_buffer, agent_audio_source)
                    audio_buffer = []
                
        except Exception as e:
            logger.error(f"‚ùå [DIAGNOSTIC] Erreur diagnostic track: {e}")
    
    async def analyze_audio_frame(self, frame: rtc.AudioFrame, frame_number: int) -> AudioDiagnosticData:
        """Analyse d√©taill√©e d'une frame audio"""
        
        try:
            # Extraire les donn√©es brutes
            data = np.frombuffer(frame.data, dtype=np.int16)
            
            # Convertir en float pour les calculs
            data_float = data.astype(np.float32) / 32768.0
            
            # Calculs de diagnostic
            energy = float(np.sqrt(np.mean(data_float**2)))
            max_amp = float(np.max(np.abs(data_float))) if len(data_float) > 0 else 0.0
            min_amp = float(np.min(data_float)) if len(data_float) > 0 else 0.0
            rms = float(np.sqrt(np.mean(data_float**2))) if len(data_float) > 0 else 0.0
            
            # Zero crossing rate
            zero_crossings = np.sum(np.diff(np.sign(data_float)) != 0) if len(data_float) > 1 else 0
            zcr = zero_crossings / len(data_float) if len(data_float) > 0 else 0.0
            
            # D√©tection de silence
            is_silent = energy < 0.001  # Seuil tr√®s bas pour diagnostic
            
            # √âchantillon des premi√®res donn√©es pour debug
            raw_sample = data_float[:10].tolist() if len(data_float) >= 10 else data_float.tolist()
            
            # Compter les frames silencieuses
            if is_silent:
                self.silent_frames_count += 1
            else:
                self.non_silent_frames_count += 1
            
            diagnostic = AudioDiagnosticData(
                timestamp=time.time(),
                frame_count=frame_number,
                sample_rate=frame.sample_rate,
                num_channels=frame.num_channels,
                data_length=len(data),
                energy=energy,
                max_amplitude=max_amp,
                min_amplitude=min_amp,
                rms=rms,
                zero_crossing_rate=zcr,
                is_silent=is_silent,
                raw_data_sample=raw_sample
            )
            
            # Log d√©taill√© pour les premi√®res frames et frames non-silencieuses
            if frame_number <= 5 or not is_silent or frame_number % 100 == 0:
                logger.info(f"üîç [FRAME {frame_number}] √ânergie: {energy:.6f}, Max: {max_amp:.6f}, RMS: {rms:.6f}, ZCR: {zcr:.3f}")
                logger.info(f"üîç [FRAME {frame_number}] Silencieux: {is_silent}, Donn√©es: {raw_sample[:5]}")
            
            return diagnostic
            
        except Exception as e:
            logger.error(f"‚ùå [DIAGNOSTIC] Erreur analyse frame {frame_number}: {e}")
            return AudioDiagnosticData(
                timestamp=time.time(),
                frame_count=frame_number,
                sample_rate=0,
                num_channels=0,
                data_length=0,
                energy=0.0,
                max_amplitude=0.0,
                min_amplitude=0.0,
                rms=0.0,
                zero_crossing_rate=0.0,
                is_silent=True,
                raw_data_sample=[]
            )
    
    async def process_audio_buffer(self, audio_buffer: List[rtc.AudioFrame], agent_audio_source):
        """Traite un buffer d'audio accumul√©"""
        
        logger.info(f"üîß [BUFFER] Traitement buffer de {len(audio_buffer)} frames")
        
        try:
            # Concat√©ner toutes les frames
            all_data = []
            for frame in audio_buffer:
                data = np.frombuffer(frame.data, dtype=np.int16)
                all_data.extend(data)
            
            if not all_data:
                logger.warning("‚ö†Ô∏è [BUFFER] Buffer vide")
                return
            
            # Convertir en numpy array
            audio_array = np.array(all_data, dtype=np.float32) / 32768.0
            
            # Analyse globale du buffer
            buffer_energy = float(np.sqrt(np.mean(audio_array**2)))
            buffer_max = float(np.max(np.abs(audio_array)))
            buffer_rms = float(np.sqrt(np.mean(audio_array**2)))
            
            logger.info(f"üìä [BUFFER] √ânergie globale: {buffer_energy:.6f}")
            logger.info(f"üìä [BUFFER] Amplitude max: {buffer_max:.6f}")
            logger.info(f"üìä [BUFFER] RMS: {buffer_rms:.6f}")
            
            # Test de traitement m√™me si "silencieux"
            if buffer_energy > 0.0001:  # Seuil tr√®s bas
                logger.info("üéØ [BUFFER] Audio d√©tect√© - traitement STT")
                await self.test_stt_processing(audio_array)
            else:
                logger.warning(f"‚ö†Ô∏è [BUFFER] Audio trop silencieux (√©nergie: {buffer_energy:.6f})")
                
                # Diagnostic approfondi pour audio silencieux
                await self.diagnose_silent_audio(audio_array)
            
        except Exception as e:
            logger.error(f"‚ùå [BUFFER] Erreur traitement buffer: {e}")
    
    async def diagnose_silent_audio(self, audio_array: np.ndarray):
        """Diagnostic approfondi pour audio silencieux"""
        
        logger.info("üîç [SILENT] === DIAGNOSTIC AUDIO SILENCIEUX ===")
        
        try:
            # Statistiques d√©taill√©es
            unique_values = np.unique(audio_array)
            logger.info(f"üîç [SILENT] Valeurs uniques: {len(unique_values)}")
            logger.info(f"üîç [SILENT] Premi√®res valeurs: {unique_values[:10]}")
            
            # V√©rifier si toutes les valeurs sont exactement 0
            all_zero = np.all(audio_array == 0)
            logger.info(f"üîç [SILENT] Toutes valeurs = 0: {all_zero}")
            
            # V√©rifier la distribution
            non_zero_count = np.count_nonzero(audio_array)
            logger.info(f"üîç [SILENT] √âchantillons non-z√©ro: {non_zero_count}/{len(audio_array)}")
            
            # Histogramme des valeurs
            if len(unique_values) <= 20:
                for val in unique_values:
                    count = np.sum(audio_array == val)
                    logger.info(f"üîç [SILENT] Valeur {val:.6f}: {count} occurrences")
            
            # Test de for√ßage pour validation pipeline
            if all_zero:
                logger.info("üîß [SILENT] Test avec audio synth√©tique...")
                synthetic_audio = np.sin(2 * np.pi * 440 * np.linspace(0, 1, len(audio_array))) * 0.1
                await self.test_stt_processing(synthetic_audio)
            
        except Exception as e:
            logger.error(f"‚ùå [SILENT] Erreur diagnostic silencieux: {e}")
    
    async def test_stt_processing(self, audio_array: np.ndarray):
        """Test du traitement STT"""
        
        logger.info("üéØ [STT] Test traitement STT...")
        
        try:
            # Simuler l'appel STT (remplacer par vraie logique)
            logger.info(f"üéØ [STT] Envoi {len(audio_array)} √©chantillons √† Whisper")
            
            # Ici on pourrait appeler le vrai service Whisper
            # Pour le diagnostic, on simule
            if np.max(np.abs(audio_array)) > 0.01:
                logger.info("‚úÖ [STT] Audio suffisant pour transcription")
            else:
                logger.warning("‚ö†Ô∏è [STT] Audio trop faible pour transcription")
            
        except Exception as e:
            logger.error(f"‚ùå [STT] Erreur test STT: {e}")
    
    async def log_diagnostic_summary(self, frame_count: int):
        """Log un r√©sum√© du diagnostic"""
        
        elapsed_time = time.time() - self.start_time
        
        logger.info(f"üìä [SUMMARY] === R√âSUM√â DIAGNOSTIC (Frame {frame_count}) ===")
        logger.info(f"üìä [SUMMARY] Temps √©coul√©: {elapsed_time:.1f}s")
        logger.info(f"üìä [SUMMARY] Frames totales: {self.total_frames_received}")
        logger.info(f"üìä [SUMMARY] Frames silencieuses: {self.silent_frames_count}")
        logger.info(f"üìä [SUMMARY] Frames non-silencieuses: {self.non_silent_frames_count}")
        
        if self.total_frames_received > 0:
            silence_ratio = self.silent_frames_count / self.total_frames_received
            logger.info(f"üìä [SUMMARY] Ratio silence: {silence_ratio:.2%}")
        
        # Derni√®res donn√©es de diagnostic
        if self.diagnostic_data:
            recent_data = self.diagnostic_data[-10:]  # 10 derni√®res frames
            avg_energy = np.mean([d.energy for d in recent_data])
            max_energy = np.max([d.energy for d in recent_data])
            logger.info(f"üìä [SUMMARY] √ânergie moyenne (10 derni√®res): {avg_energy:.6f}")
            logger.info(f"üìä [SUMMARY] √ânergie max (10 derni√®res): {max_energy:.6f}")
    
    async def start_continuous_monitoring(self, ctx: JobContext, audio_source: rtc.AudioSource):
        """D√©marrage du monitoring continu"""
        
        logger.info("üîÑ [MONITOR] === D√âMARRAGE MONITORING CONTINU ===")
        
        try:
            monitor_counter = 0
            
            while True:
                # Attendre 15 secondes entre chaque rapport
                await asyncio.sleep(15)
                
                monitor_counter += 1
                logger.info(f"üîÑ [MONITOR] Rapport #{monitor_counter}")
                
                # G√©n√©rer rapport de diagnostic
                await self.generate_diagnostic_report(monitor_counter)
                
                # Test audio p√©riodique pour v√©rifier la publication
                if monitor_counter % 4 == 0:  # Toutes les minutes
                    await self.test_audio_publication(audio_source)
                
        except Exception as e:
            logger.error(f"‚ùå [MONITOR] Erreur monitoring: {e}")
    
    async def generate_diagnostic_report(self, report_number: int):
        """G√©n√®re un rapport de diagnostic complet"""
        
        logger.info(f"üìã [REPORT] === RAPPORT DIAGNOSTIC #{report_number} ===")
        
        try:
            elapsed_time = time.time() - self.start_time
            
            # Statistiques globales
            logger.info(f"üìã [REPORT] Dur√©e session: {elapsed_time:.1f}s")
            logger.info(f"üìã [REPORT] Frames totales re√ßues: {self.total_frames_received}")
            logger.info(f"üìã [REPORT] Frames silencieuses: {self.silent_frames_count}")
            logger.info(f"üìã [REPORT] Frames avec audio: {self.non_silent_frames_count}")
            
            if self.total_frames_received > 0:
                silence_ratio = self.silent_frames_count / self.total_frames_received
                logger.info(f"üìã [REPORT] Taux de silence: {silence_ratio:.2%}")
                
                # Diagnostic du probl√®me
                if silence_ratio > 0.95:
                    logger.error("‚ùå [REPORT] PROBL√àME CRITIQUE: >95% de frames silencieuses")
                    logger.error("‚ùå [REPORT] Causes possibles:")
                    logger.error("‚ùå [REPORT] 1. Permissions microphone non accord√©es")
                    logger.error("‚ùå [REPORT] 2. Microphone d√©faillant")
                    logger.error("‚ùå [REPORT] 3. Configuration audio incorrecte")
                    logger.error("‚ùå [REPORT] 4. Probl√®me de transmission LiveKit")
                elif silence_ratio > 0.8:
                    logger.warning("‚ö†Ô∏è [REPORT] ATTENTION: >80% de frames silencieuses")
                else:
                    logger.info("‚úÖ [REPORT] Niveau audio acceptable")
            
            # Analyse des derni√®res donn√©es
            if self.diagnostic_data:
                recent_data = self.diagnostic_data[-50:]  # 50 derni√®res frames
                energies = [d.energy for d in recent_data]
                
                if energies:
                    avg_energy = np.mean(energies)
                    max_energy = np.max(energies)
                    min_energy = np.min(energies)
                    
                    logger.info(f"üìã [REPORT] √ânergie r√©cente - Moy: {avg_energy:.6f}, Max: {max_energy:.6f}, Min: {min_energy:.6f}")
            
        except Exception as e:
            logger.error(f"‚ùå [REPORT] Erreur g√©n√©ration rapport: {e}")
    
    async def test_audio_publication(self, audio_source: rtc.AudioSource):
        """Test de publication audio pour v√©rifier le pipeline sortant"""
        
        logger.info("üéµ [TEST] Test publication audio...")
        
        try:
            # G√©n√©rer un signal de test
            sample_rate = 24000
            duration = 2.0
            frequency = 880  # Note A5
            
            t = np.linspace(0, duration, int(sample_rate * duration))
            test_signal = np.sin(2 * np.pi * frequency * t) * 0.2
            
            # Convertir en int16
            test_audio = (test_signal * 32767).astype(np.int16)
            
            # Publier par chunks
            samples_per_frame = 240  # 10ms √† 24kHz
            
            for i in range(0, len(test_audio), samples_per_frame):
                frame_samples = test_audio[i:i+samples_per_frame]
                
                if len(frame_samples) == samples_per_frame:
                    audio_frame = rtc.AudioFrame.create(
                        sample_rate=24000,
                        num_channels=1,
                        samples_per_channel=samples_per_frame
                    )
                    
                    audio_frame.data[:len(frame_samples)*2] = frame_samples.tobytes()
                    await audio_source.capture_frame(audio_frame)
                    await asyncio.sleep(0.01)
            
            logger.info("‚úÖ [TEST] Signal de test publi√©")
            
        except Exception as e:
            logger.error(f"‚ùå [TEST] Erreur test publication: {e}")

# Point d'entr√©e pour l'agent de diagnostic
async def diagnostic_entrypoint(ctx: JobContext):
    """Point d'entr√©e pour l'agent de diagnostic"""
    diagnostic_agent = AudioDiagnosticAgent()
    await diagnostic_agent.entrypoint(ctx)

if __name__ == "__main__":
    print("üîç [DIAGNOSTIC] D√©marrage agent de diagnostic audio...")
    
    async def main():
        try:
            worker_opts = agents.WorkerOptions(
                entrypoint_fnc=diagnostic_entrypoint,
                ws_url=os.environ.get("LIVEKIT_URL"),
                api_key=os.environ.get("LIVEKIT_API_KEY"),
                api_secret=os.environ.get("LIVEKIT_API_SECRET")
            )
            
            worker = agents.Worker(worker_opts)
            await worker.run()
            
        except Exception as e:
            print(f"‚ùå [DIAGNOSTIC] Erreur: {e}")
            raise
    
    asyncio.run(main())