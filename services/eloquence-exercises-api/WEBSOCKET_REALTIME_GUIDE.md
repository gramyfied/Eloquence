# Guide WebSocket - Analyse Vocale Temps R√©el

## Vue d'ensemble

L'API Eloquence Exercises propose un endpoint WebSocket pour l'analyse vocale en temps r√©el, permettant une communication bidirectionnelle continue pour traiter et analyser la parole de mani√®re fluide.

## Endpoint WebSocket

```
ws://localhost:8001/ws/voice-analysis/{session_id}
```

### Param√®tres

- `session_id` (string) : Identifiant unique de la session d'analyse temps r√©el

## Protocole de Communication

### 1. Flux de Communication Standard

```mermaid
sequenceDiagram
    participant Client
    participant WebSocket
    participant Vosk
    
    Client->>WebSocket: Connexion
    WebSocket-->>Client: Connexion accept√©e
    
    Client->>WebSocket: START_SESSION
    WebSocket-->>Client: session_started
    
    loop Analyse temps r√©el
        Client->>WebSocket: AUDIO_CHUNK
        WebSocket->>Vosk: Analyse audio
        Vosk-->>WebSocket: R√©sultat transcription
        WebSocket-->>Client: PARTIAL_RESULT
        
        Note over WebSocket: Toutes les 5 chunks
        WebSocket-->>Client: METRICS_UPDATE
    end
    
    Client->>WebSocket: END_SESSION
    WebSocket-->>Client: FINAL_RESULT
    Client->>WebSocket: D√©connexion
```

## Types de Messages

### 1. Messages Entrants (Client ‚Üí Serveur)

#### START_SESSION
Initialise une nouvelle session d'analyse temps r√©el.

```json
{
  "type": "START_SESSION",
  "session_id": "session_unique_123",
  "exercise_type": "pronunciation_practice",
  "user_id": "user_456",
  "settings": {
    "target_language": "fr",
    "difficulty_level": "intermediate"
  }
}
```

**Champs requis :**
- `type` : "START_SESSION"
- `session_id` : Identifiant unique de la session
- `exercise_type` : Type d'exercice (pronunciation_practice, fluency_training, etc.)
- `user_id` : Identifiant de l'utilisateur

**Champs optionnels :**
- `settings` : Configuration sp√©cifique de l'exercice

#### AUDIO_CHUNK
Envoie un chunk audio pour analyse.

```json
{
  "type": "AUDIO_CHUNK",
  "session_id": "session_unique_123",
  "chunk_id": 42,
  "audio_data": "UklGRjIAAABXQVZFZm10IBAAAAABAAEA...",
  "timestamp": "2025-01-26T10:30:45.123Z",
  "metadata": {
    "duration": 0.5,
    "sample_rate": 16000,
    "channels": 1
  }
}
```

**Champs requis :**
- `type` : "AUDIO_CHUNK"
- `session_id` : Identifiant de la session
- `chunk_id` : Num√©ro s√©quentiel du chunk
- `audio_data` : Donn√©es audio encod√©es en base64 (format WAV)
- `timestamp` : Horodatage ISO 8601

**Champs optionnels :**
- `metadata` : M√©tadonn√©es audio (dur√©e, √©chantillonnage, etc.)

#### END_SESSION
Termine la session et demande les r√©sultats finaux.

```json
{
  "type": "END_SESSION",
  "session_id": "session_unique_123",
  "timestamp": "2025-01-26T10:31:30.456Z"
}
```

### 2. Messages Sortants (Serveur ‚Üí Client)

#### session_started
Confirmation de d√©marrage de session.

```json
{
  "type": "session_started",
  "session_id": "session_unique_123",
  "timestamp": "2025-01-26T10:30:45.123Z"
}
```

#### PARTIAL_RESULT
R√©sultat partiel d'analyse d'un chunk audio.

```json
{
  "type": "PARTIAL_RESULT",
  "session_id": "session_unique_123",
  "chunk_id": 42,
  "transcription": "bonjour comment allez-vous",
  "confidence": 0.87,
  "timestamp": "2025-01-26T10:30:45.678Z",
  "partial_metrics": {
    "chunk_confidence": 0.87,
    "chunk_duration": 0.5
  }
}
```

#### METRICS_UPDATE
Mise √† jour des m√©triques temps r√©el (envoy√©e toutes les 5 chunks).

```json
{
  "type": "METRICS_UPDATE",
  "session_id": "session_unique_123",
  "timestamp": "2025-01-26T10:30:48.123Z",
  "clarity_score": 0.83,
  "fluency_score": 0.76,
  "energy_score": 0.62,
  "speaking_rate": 142.5,
  "pause_ratio": 0.18,
  "cumulative_confidence": 0.81
}
```

#### FINAL_RESULT
R√©sultat final complet de la session.

```json
{
  "type": "FINAL_RESULT",
  "session_id": "session_unique_123",
  "total_duration": 25.3,
  "final_transcription": "bonjour comment allez-vous aujourd'hui",
  "overall_metrics": {
    "clarity_score": 0.85,
    "fluency_score": 0.78,
    "energy_score": 0.65,
    "speaking_rate": 138.2,
    "pause_ratio": 0.22,
    "cumulative_confidence": 0.82
  },
  "strengths": [
    "Excellente clart√© de prononciation",
    "D√©bit de parole optimal"
  ],
  "improvements": [
    "R√©duire les pauses"
  ],
  "feedback": "Session de 25.3s avec 50 chunks analys√©s.",
  "processing_time": 0.0
}
```

#### ERROR
Message d'erreur en cas de probl√®me.

```json
{
  "type": "ERROR",
  "session_id": "session_unique_123",
  "error_code": "INVALID_JSON",
  "error_message": "Format JSON invalide",
  "timestamp": "2025-01-26T10:30:45.123Z"
}
```

## Format Audio Requis

### Sp√©cifications Audio
- **Format** : WAV (PCM non compress√©)
- **√âchantillonnage** : 16 kHz (recommand√©)
- **Channels** : 1 (mono)
- **Bit depth** : 16 bits
- **Encodage** : Base64

### Dur√©e des Chunks
- **Recommand√©e** : 0.5 secondes (500ms)
- **Minimum** : 0.1 secondes
- **Maximum** : 2.0 secondes

### Exemple de Pr√©paration Audio (Python)

```python
import wave
import base64
import io

def prepare_audio_chunk(audio_data: bytes, sample_rate: int = 16000) -> str:
    """Pr√©pare un chunk audio pour envoi WebSocket"""
    # Cr√©er un fichier WAV en m√©moire
    wav_buffer = io.BytesIO()
    with wave.open(wav_buffer, 'wb') as wav_file:
        wav_file.setnchannels(1)  # Mono
        wav_file.setsampwidth(2)  # 16 bits
        wav_file.setframerate(sample_rate)
        wav_file.writeframes(audio_data)
    
    # Encoder en base64
    wav_data = wav_buffer.getvalue()
    return base64.b64encode(wav_data).decode('utf-8')
```

## M√©triques Temps R√©el

### Description des M√©triques

| M√©trique | Description | Plage | Interpr√©tation |
|----------|-------------|-------|----------------|
| `clarity_score` | Clart√© de prononciation | 0.0 - 1.0 | Bas√© sur la confiance de transcription |
| `fluency_score` | Fluidit√© de la parole | 0.0 - 1.0 | Inverse du ratio de pauses |
| `energy_score` | √ânergie/dynamisme | 0.0 - 1.0 | Bas√© sur le d√©bit de parole |
| `speaking_rate` | D√©bit en mots/minute | 0+ | Vitesse d'√©locution |
| `pause_ratio` | Ratio de pauses | 0.0 - 1.0 | Proportion de chunks silencieux |
| `cumulative_confidence` | Confiance moyenne | 0.0 - 1.0 | Confiance globale |

### Interpr√©tation des Scores

**Clarity Score (Clart√©)**
- `0.8 - 1.0` : Excellente clart√©
- `0.6 - 0.8` : Bonne clart√©
- `0.4 - 0.6` : Clart√© mod√©r√©e
- `< 0.4` : Am√©lioration n√©cessaire

**Speaking Rate (D√©bit)**
- `120 - 160 mots/min` : Optimal
- `100 - 120 mots/min` : Lent mais acceptable
- `160 - 200 mots/min` : Rapide mais compr√©hensible
- `< 100 ou > 200 mots/min` : √Ä ajuster

## Gestion d'Erreurs

### Codes d'Erreur Communs

| Code | Description | Action recommand√©e |
|------|-------------|-------------------|
| `INVALID_JSON` | Format JSON invalide | V√©rifier la structure du message |
| `MISSING_FIELD` | Champ requis manquant | Ajouter les champs obligatoires |
| `VOSK_ERROR` | Erreur service Vosk | V√©rifier la connectivit√© Vosk |
| `AUDIO_FORMAT_ERROR` | Format audio invalide | V√©rifier l'encodage base64/WAV |
| `SESSION_NOT_FOUND` | Session inconnue | D√©marrer une nouvelle session |
| `PROCESSING_ERROR` | Erreur de traitement | R√©essayer ou contacter le support |

### Strat√©gies de R√©cup√©ration

1. **Reconnexion automatique** : En cas de d√©connexion
2. **Retry logic** : Pour les erreurs temporaires
3. **Validation c√¥t√© client** : Avant envoi des messages
4. **Bufferisation** : Pour g√©rer les latences r√©seau

## Exemples d'Utilisation

### Exemple Python (Client)

```python
import asyncio
import websockets
import json
import base64

async def realtime_voice_analysis():
    uri = "ws://localhost:8001/ws/voice-analysis/my_session_123"
    
    async with websockets.connect(uri) as websocket:
        # 1. D√©marrer la session
        start_msg = {
            "type": "START_SESSION",
            "session_id": "my_session_123",
            "exercise_type": "pronunciation_practice",
            "user_id": "user_456"
        }
        await websocket.send(json.dumps(start_msg))
        
        # Attendre confirmation
        response = await websocket.recv()
        print(f"Session started: {response}")
        
        # 2. Envoyer des chunks audio
        for chunk_id in range(1, 11):
            # Pr√©parer chunk audio (exemple)
            audio_data = prepare_audio_chunk(get_audio_data())
            
            chunk_msg = {
                "type": "AUDIO_CHUNK",
                "session_id": "my_session_123",
                "chunk_id": chunk_id,
                "audio_data": audio_data,
                "timestamp": datetime.now().isoformat()
            }
            await websocket.send(json.dumps(chunk_msg))
            
            # Recevoir r√©sultat partiel
            result = await websocket.recv()
            partial = json.loads(result)
            print(f"Chunk {chunk_id}: {partial.get('transcription')}")
        
        # 3. Terminer la session
        end_msg = {
            "type": "END_SESSION",
            "session_id": "my_session_123",
            "timestamp": datetime.now().isoformat()
        }
        await websocket.send(json.dumps(end_msg))
        
        # Recevoir r√©sultat final
        final_result = await websocket.recv()
        print(f"Final result: {final_result}")

# Ex√©cuter
asyncio.run(realtime_voice_analysis())
```

### Exemple JavaScript (Browser)

```javascript
class RealtimeVoiceAnalyzer {
    constructor(sessionId) {
        this.sessionId = sessionId;
        this.websocket = null;
    }
    
    async connect() {
        const url = `ws://localhost:8001/ws/voice-analysis/${this.sessionId}`;
        this.websocket = new WebSocket(url);
        
        this.websocket.onopen = () => {
            console.log('üîå WebSocket connect√©');
            this.startSession();
        };
        
        this.websocket.onmessage = (event) => {
            const message = JSON.parse(event.data);
            this.handleMessage(message);
        };
        
        this.websocket.onerror = (error) => {
            console.error('‚ùå Erreur WebSocket:', error);
        };
    }
    
    startSession() {
        const message = {
            type: 'START_SESSION',
            session_id: this.sessionId,
            exercise_type: 'pronunciation_practice',
            user_id: 'user_123'
        };
        this.websocket.send(JSON.stringify(message));
    }
    
    sendAudioChunk(audioBlob, chunkId) {
        const reader = new FileReader();
        reader.onload = () => {
            const base64Audio = btoa(reader.result);
            const message = {
                type: 'AUDIO_CHUNK',
                session_id: this.sessionId,
                chunk_id: chunkId,
                audio_data: base64Audio,
                timestamp: new Date().toISOString()
            };
            this.websocket.send(JSON.stringify(message));
        };
        reader.readAsBinaryString(audioBlob);
    }
    
    handleMessage(message) {
        switch(message.type) {
            case 'session_started':
                console.log('‚úÖ Session d√©marr√©e');
                break;
            case 'PARTIAL_RESULT':
                console.log(`üé§ Transcription: ${message.transcription}`);
                break;
            case 'METRICS_UPDATE':
                console.log(`üìä M√©triques:`, message);
                break;
            case 'FINAL_RESULT':
                console.log(`üéâ R√©sultat final:`, message);
                break;
            case 'ERROR':
                console.error(`‚ùå Erreur: ${message.error_message}`);
                break;
        }
    }
    
    endSession() {
        const message = {
            type: 'END_SESSION',
            session_id: this.sessionId,
            timestamp: new Date().toISOString()
        };
        this.websocket.send(JSON.stringify(message));
    }
}

// Utilisation
const analyzer = new RealtimeVoiceAnalyzer('session_456');
analyzer.connect();
```

## Tests et Validation

### Script de Test Inclus
Utilisez le script [`test_websocket_realtime.py`](./test_websocket_realtime.py) pour valider l'endpoint :

```bash
# D√©marrer l'API
docker-compose up eloquence-exercises-api

# Ex√©cuter les tests
cd services/eloquence-exercises-api
python test_websocket_realtime.py
```

### Tests Manuels avec Postman/Insomnia
1. Cr√©er une connexion WebSocket vers `ws://localhost:8001/ws/voice-analysis/test_session`
2. Envoyer les messages selon le protocole d√©fini
3. V√©rifier les r√©ponses et m√©triques

## Limitations et Consid√©rations

### Performance
- **Latence** : ~100-500ms par chunk (selon la taille)
- **Throughput** : ~10-20 chunks/seconde maximum
- **M√©moire** : Chaque session active utilise ~50MB

### Contraintes R√©seau
- **Bande passante** : ~64 kbps pour audio 16kHz mono
- **Timeout** : 5 secondes maximum par chunk
- **Buffer** : Chunks trop rapides peuvent √™tre ignor√©s

### S√©curit√©
- **Authentification** : √Ä impl√©menter selon les besoins
- **Rate limiting** : Pas encore impl√©ment√©
- **Validation** : Format audio strictement valid√©

## Support et D√©pannage

### Logs Utiles
```bash
# Logs du service
docker-compose logs eloquence-exercises-api

# Logs Vosk
docker-compose logs vosk-stt-analysis
```

### Probl√®mes Fr√©quents

**Connexion WebSocket √©choue**
- V√©rifier que le service est d√©marr√©
- Contr√¥ler les ports (8001)
- Tester la connectivit√© de base

**Audio non reconnu**
- V√©rifier le format WAV + Base64
- Contr√¥ler l'√©chantillonnage (16kHz)
- Valider la dur√©e des chunks

**M√©triques incoh√©rentes**
- V√©rifier la s√©quence des chunk_id
- Contr√¥ler la temporisation des envois
- Valider la qualit√© audio source

---

*Documentation g√©n√©r√©e pour l'API Eloquence Exercises - Version WebSocket Temps R√©el*