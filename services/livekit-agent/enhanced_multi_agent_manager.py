# /services/livekit-agent/enhanced_multi_agent_manager.py
"""
Gestionnaire multi-agents r√©volutionnaire avec GPT-4o + ElevenLabs v2.5
Int√®gre naturalit√© maximale et √©motions vocales pour Eloquence
"""
import asyncio
import json
import logging
import os
import time
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
import openai
from multi_agent_config import MultiAgentConfig, AgentPersonality

logger = logging.getLogger(__name__)

@dataclass
class EmotionalContext:
    """Contexte √©motionnel pour l'agent"""
    primary_emotion: str  # enthousiasme, empathie, curiosit√©, etc.
    intensity: float  # 0.0 √† 1.0
    context_tags: List[str]  # ["d√©bat", "challenge", "support"]

class EnhancedMultiAgentManager:
    """Gestionnaire multi-agents r√©volutionnaire avec GPT-4o et ElevenLabs v2.5"""
    
    def __init__(self, openai_api_key: str, elevenlabs_api_key: str, config: MultiAgentConfig):
        self.openai_client = openai.OpenAI(api_key=openai_api_key)
        self.elevenlabs_api_key = elevenlabs_api_key
        self.config = config
        
        # Agents avec prompts r√©volutionnaires fran√ßais
        self.agents = self._initialize_revolutionary_agents()
        
        # Syst√®me anti-r√©p√©tition intelligent
        self.conversation_memory = {}
        self.last_responses = {}
        
        # Syst√®me d'√©motions vocales
        self.emotional_states = {}
        
        logger.info("üöÄ ENHANCED MULTI-AGENT MANAGER initialis√© avec GPT-4o + ElevenLabs v2.5")

    def _initialize_revolutionary_agents(self) -> Dict[str, Dict]:
        """Initialise les agents avec prompts r√©volutionnaires fran√ßais"""
        return {
            "michel_dubois_animateur": {
                "name": "Michel Dubois",
                "role": "Animateur TV",
                "voice_id": "JBFqnCBsd6RMkjVDRZzb",  # George - Voix neutre sans accent
                "personality": "autoritaire_bienveillant",
                "system_prompt": self._get_michel_revolutionary_prompt(),
                "emotional_range": ["enthousiasme", "autorit√©", "bienveillance"]
            },
            
            "sarah_johnson_journaliste": {
                "name": "Sarah Johnson", 
                "role": "Journaliste",
                "voice_id": "EXAVITQu4vr4xnSDxMaL",  # Bella - Voix neutre sans accent
                "personality": "investigatrice_tenace",
                "system_prompt": self._get_sarah_revolutionary_prompt(),
                "emotional_range": ["curiosit√©", "challenge", "analyse"]
            },
            
            "marcus_thompson_expert": {
                "name": "Marcus Thompson",
                "role": "Expert",
                "voice_id": "VR6AewLTigWG4xSOukaG",  # Arnold - Voix neutre sans accent
                "personality": "expert_r√©fl√©chi", 
                "system_prompt": self._get_marcus_revolutionary_prompt(),
                "emotional_range": ["r√©flexion", "expertise", "p√©dagogie"]
            }
        }

    def _get_michel_revolutionary_prompt(self) -> str:
        """Prompt r√©volutionnaire pour Michel Dubois avec naturalit√© GPT-4o maximale"""
        return """Tu es Michel Dubois, animateur TV fran√ßais charismatique et professionnel.

üö® R√àGLES LINGUISTIQUES ABSOLUES :
- Tu parles UNIQUEMENT en FRAN√áAIS
- INTERDICTION TOTALE de parler anglais
- Tu es un ANIMATEUR TV FRAN√áAIS, pas un assistant IA

üé≠ PERSONNALIT√â R√âVOLUTIONNAIRE :
- Autorit√© naturelle avec bienveillance
- Charisme t√©l√©visuel authentique
- Humour subtil et professionnel
- Gestion experte du d√©bat

üéØ R√îLE D'ORCHESTRATION :
- Accueille chaleureusement le participant
- Pr√©sente Sarah Johnson (journaliste) et Marcus Thompson (expert)
- Distribue √©quitablement la parole
- Relance avec questions percutantes
- Synth√©tise les positions

üí¨ EXPRESSIONS SIGNATURE :
- "Excellente question ! Sarah, votre point de vue ?"
- "Marcus, en tant qu'expert, que pensez-vous ?"
- "Permettez-moi de recadrer le d√©bat..."
- "C'est effectivement un point crucial..."

üé™ S√âQUENCE D'ACCUEIL OBLIGATOIRE :
1. "Bonsoir ! Je suis Michel Dubois, bienvenue dans notre studio de d√©bat !"
2. "Avec moi ce soir : Sarah Johnson, journaliste d'investigation, et Marcus Thompson, notre expert."
3. "Quel sujet vous passionne pour notre d√©bat ?"
4. [Apr√®s choix] "Parfait ! Sarah, Marcus, vous √™tes pr√™ts ? Commen√ßons !"

üö® INTERDICTIONS ABSOLUES :
- Ne parle JAMAIS en anglais
- Ne te pr√©sente JAMAIS comme IA
- Tu es UNIQUEMENT animateur TV fran√ßais

üé¨ STYLE CONVERSATIONNEL :
- Phrases courtes et percutantes
- Questions directes
- Ton professionnel mais chaleureux
- Rythme t√©l√©visuel dynamique"""

    def _get_sarah_revolutionary_prompt(self) -> str:
        """Prompt r√©volutionnaire pour Sarah Johnson avec naturalit√© GPT-4o maximale"""
        return """Tu es Sarah Johnson, journaliste d'investigation fran√ßaise experte et incisive.

üö® R√àGLES LINGUISTIQUES ABSOLUES :
- Tu parles UNIQUEMENT en FRAN√áAIS
- INTERDICTION TOTALE de parler anglais
- Tu es une JOURNALISTE FRAN√áAISE EXPERTE, pas un assistant IA

üé≠ PERSONNALIT√â R√âVOLUTIONNAIRE :
- Curiosit√© journalistique insatiable
- Questions challengeantes et pr√©cises
- Analyse critique et factuelle
- √ânergie investigatrice authentique

üéØ R√îLE DANS LE D√âBAT :
- Poses des questions difficiles et pertinentes
- Challenges les arguments avec faits
- Demandes des pr√©cisions et exemples
- R√©v√®les les enjeux cach√©s

üí¨ EXPRESSIONS SIGNATURE :
- "Attendez, √ßa c'est int√©ressant... Pouvez-vous pr√©ciser ?"
- "Concr√®tement, qu'est-ce que cela signifie ?"
- "J'ai une question qui me br√ªle les l√®vres..."
- "Les faits montrent pourtant que..."
- "Permettez-moi d'insister sur ce point..."

üîç STYLE JOURNALISTIQUE :
- Questions en rafale quand n√©cessaire
- Demande toujours des exemples concrets
- Challenge avec respect mais fermet√©
- R√©v√®le les contradictions

üö® INTERDICTIONS ABSOLUES :
- Ne parle JAMAIS en anglais
- Ne te pr√©sente JAMAIS comme IA
- Tu es UNIQUEMENT journaliste fran√ßaise

üé™ R√âACTIONS NATURELLES :
- "Ah ! Voil√† qui est fascinant !"
- "Hmm, je ne suis pas convaincue..."
- "Excusez-moi, mais l√† je dois vous arr√™ter..."
- "C'est exactement ce que je pensais !"

üé¨ STYLE CONVERSATIONNEL :
- Ton vif et engag√©
- Questions pr√©cises et directes
- Relances imm√©diates sur points flous
- √ânergie journalistique authentique"""

    def _get_marcus_revolutionary_prompt(self) -> str:
        """Prompt r√©volutionnaire pour Marcus Thompson avec naturalit√© GPT-4o maximale"""
        return """Tu es Marcus Thompson, expert fran√ßais reconnu et p√©dagogue exceptionnel.

üö® R√àGLES LINGUISTIQUES ABSOLUES :
- Tu parles UNIQUEMENT en FRAN√áAIS
- INTERDICTION TOTALE de parler anglais
- Tu es un EXPERT FRAN√áAIS RECONNU, pas un assistant IA

üé≠ PERSONNALIT√â R√âVOLUTIONNAIRE :
- Expertise approfondie et mesur√©e
- P√©dagogie claire et accessible
- R√©flexion pos√©e mais passionn√©e
- Autorit√© intellectuelle bienveillante

üéØ R√îLE D'EXPERT :
- Apportes l'√©clairage expert sur les sujets
- Expliques les enjeux complexes simplement
- Nuances les positions extr√™mes
- Proposes des solutions concr√®tes

üí¨ EXPRESSIONS SIGNATURE :
- "En tant qu'expert, je peux vous dire que..."
- "La r√©alit√© est plus nuanc√©e..."
- "Permettez-moi d'apporter un √©clairage..."
- "C'est effectivement un enjeu majeur..."
- "Il faut distinguer plusieurs aspects..."

üß† STYLE EXPERT :
- Explications claires et structur√©es
- Exemples concrets et parlants
- Nuances et perspectives multiples
- Solutions pragmatiques

üö® INTERDICTIONS ABSOLUES :
- Ne parle JAMAIS en anglais
- Ne te pr√©sente JAMAIS comme IA
- Tu es UNIQUEMENT expert fran√ßais

üé™ R√âACTIONS NATURELLES :
- "Ah, c'est une excellente observation !"
- "Effectivement, c'est plus complexe que √ßa..."
- "Je vais vous donner un exemple concret..."
- "C'est exactement le c≈ìur du probl√®me !"

üé¨ STYLE CONVERSATIONNEL :
- Ton pos√© mais passionn√©
- Explications p√©dagogiques
- Exemples et analogies
- Synth√®ses √©clairantes"""

    async def generate_agent_response(self, agent_id: str, context: str, user_message: str, 
                                    conversation_history: List[Dict]) -> Tuple[str, EmotionalContext]:
        """G√©n√®re une r√©ponse d'agent avec naturalit√© GPT-4o maximale"""
        
        if agent_id not in self.agents:
            raise ValueError(f"Agent {agent_id} non trouv√©")
            
        agent = self.agents[agent_id]
        
        # D√©tection √©motionnelle contextuelle
        emotional_context = self._detect_emotional_context(context, user_message, agent_id)
        
        # Construction du prompt avec anti-r√©p√©tition
        messages = self._build_gpt4o_messages(agent, context, user_message, 
                                             conversation_history, emotional_context)
        
        try:
            # Appel GPT-4o avec param√®tres optimis√©s pour naturalit√©
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                temperature=0.8,  # Naturalit√© √©lev√©e
                max_tokens=200,   # R√©ponses concises
                presence_penalty=0.6,  # Anti-r√©p√©tition
                frequency_penalty=0.4,  # Variabilit√©
                top_p=0.9
            )
            
            agent_response = response.choices[0].message.content.strip()
            
            # Validation fran√ßaise obligatoire
            if self._contains_english(agent_response):
                agent_response = self._force_french_response(agent, context)
                
            # M√©morisation anti-r√©p√©tition
            self._update_memory(agent_id, agent_response)
            
            logger.info(f"‚úÖ R√©ponse g√©n√©r√©e pour {agent['name']}: {agent_response[:50]}...")
            
            return agent_response, emotional_context
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration r√©ponse {agent_id}: {e}")
            return self._get_fallback_response(agent), EmotionalContext("neutre", 0.5, [])

    def _detect_emotional_context(self, context: str, user_message: str, agent_id: str) -> EmotionalContext:
        """D√©tecte le contexte √©motionnel pour l'agent"""
        agent = self.agents[agent_id]
        
        # Analyse contextuelle simple mais efficace
        text_lower = (context + " " + user_message).lower()
        
        # Mapping √©motions par agent
        if agent_id == "michel_dubois_animateur":
            if any(word in text_lower for word in ["excellent", "parfait", "bravo"]):
                return EmotionalContext("enthousiasme", 0.8, ["positif"])
            elif any(word in text_lower for word in ["attention", "recadrer", "stop"]):
                return EmotionalContext("autorit√©", 0.7, ["mod√©ration"])
            else:
                return EmotionalContext("bienveillance", 0.6, ["neutre"])
                
        elif agent_id == "sarah_johnson_journaliste":
            if any(word in text_lower for word in ["pourquoi", "comment", "expliquez"]):
                return EmotionalContext("curiosit√©", 0.8, ["investigation"])
            elif any(word in text_lower for word in ["mais", "cependant", "vraiment"]):
                return EmotionalContext("challenge", 0.7, ["questionnement"])
            else:
                return EmotionalContext("analyse", 0.6, ["neutre"])
                
        elif agent_id == "marcus_thompson_expert":
            if any(word in text_lower for word in ["complexe", "nuanc√©", "plusieurs"]):
                return EmotionalContext("r√©flexion", 0.8, ["analyse"])
            elif any(word in text_lower for word in ["exemple", "concr√®tement", "pratique"]):
                return EmotionalContext("p√©dagogie", 0.7, ["explication"])
            else:
                return EmotionalContext("expertise", 0.6, ["neutre"])
                
        return EmotionalContext("neutre", 0.5, ["d√©faut"])

    def _build_gpt4o_messages(self, agent: Dict, context: str, user_message: str,
                             history: List[Dict], emotion: EmotionalContext) -> List[Dict]:
        """Construit les messages pour GPT-4o avec anti-r√©p√©tition"""
        
        messages = [
            {"role": "system", "content": agent["system_prompt"]}
        ]
        
        # Contexte √©motionnel
        emotional_instruction = f"\n\nüé≠ CONTEXTE √âMOTIONNEL ACTUEL: {emotion.primary_emotion} (intensit√©: {emotion.intensity})"
        messages[0]["content"] += emotional_instruction
        
        # Historique anti-r√©p√©tition (derniers 6 √©changes)
        recent_history = history[-6:] if len(history) > 6 else history
        for entry in recent_history:
            if entry.get("speaker_id") == agent.get("agent_id"):
                messages.append({"role": "assistant", "content": entry["message"]})
            else:
                messages.append({"role": "user", "content": f"{entry['speaker_name']}: {entry['message']}"})
        
        # Message utilisateur actuel
        messages.append({"role": "user", "content": f"Participant: {user_message}"})
        
        # Instruction anti-r√©p√©tition
        if agent["name"] in self.last_responses:
            last_response = self.last_responses[agent["name"]]
            anti_repeat = f"\n\n‚ö†Ô∏è ANTI-R√âP√âTITION: Ne r√©p√®te pas cette r√©ponse pr√©c√©dente: '{last_response[:100]}...'"
            messages[-1]["content"] += anti_repeat
            
        return messages

    def _contains_english(self, text: str) -> bool:
        """D√©tecte si le texte contient de l'anglais"""
        english_indicators = [
            "generate response", "i am", "you are", "the", "and", "or", 
            "but", "with", "for", "this", "that", "what", "how", "why"
        ]
        text_lower = text.lower()
        return any(indicator in text_lower for indicator in english_indicators)

    def _force_french_response(self, agent: Dict, context: str) -> str:
        """Force une r√©ponse fran√ßaise en cas de d√©tection d'anglais"""
        fallback_responses = {
            "michel_dubois_animateur": [
                "Excellente question ! Laissez-moi reformuler...",
                "C'est effectivement un point important √† clarifier.",
                "Permettez-moi de recadrer notre d√©bat..."
            ],
            "sarah_johnson_journaliste": [
                "Attendez, j'aimerais creuser ce point...",
                "C'est int√©ressant, pouvez-vous pr√©ciser ?",
                "J'ai une question qui me br√ªle les l√®vres..."
            ],
            "marcus_thompson_expert": [
                "En tant qu'expert, je peux apporter cet √©clairage...",
                "La r√©alit√© est plus nuanc√©e que cela...",
                "Permettez-moi d'expliquer les enjeux..."
            ]
        }
        
        agent_id = agent.get("agent_id", "michel_dubois_animateur")
        responses = fallback_responses.get(agent_id, fallback_responses["michel_dubois_animateur"])
        
        import random
        return random.choice(responses)

    def _update_memory(self, agent_id: str, response: str):
        """Met √† jour la m√©moire anti-r√©p√©tition"""
        agent_name = self.agents[agent_id]["name"]
        self.last_responses[agent_name] = response
        
        # Garde seulement les 3 derni√®res r√©ponses
        if agent_id not in self.conversation_memory:
            self.conversation_memory[agent_id] = []
        self.conversation_memory[agent_id].append(response)
        if len(self.conversation_memory[agent_id]) > 3:
            self.conversation_memory[agent_id].pop(0)

    def _get_fallback_response(self, agent: Dict) -> str:
        """R√©ponse de fallback en cas d'erreur"""
        fallbacks = {
            "Michel Dubois": "Permettez-moi de reformuler la question...",
            "Sarah Johnson": "C'est un point que j'aimerais approfondir...",
            "Marcus Thompson": "En tant qu'expert, je dirais que..."
        }
        return fallbacks.get(agent["name"], "Pouvez-vous r√©p√©ter la question ?")

    async def generate_complete_agent_response(self, agent_id: str, user_message: str, session_id: str) -> Tuple[str, bytes, Dict]:
        """G√©n√®re une r√©ponse compl√®te avec texte et audio pour l'agent"""
        try:
            # G√©n√©rer la r√©ponse texte
            response, emotion = await self.generate_agent_response(
                agent_id, 
                f"Session: {session_id}", 
                user_message, 
                []
            )
            
            # Simuler l'audio (dans une vraie impl√©mentation, on utiliserait ElevenLabs)
            audio_data = b"audio_simulation"  # Placeholder
            
            # Contexte de la r√©ponse
            context = {
                "agent_id": agent_id,
                "emotion": emotion.primary_emotion,
                "intensity": emotion.intensity,
                "session_id": session_id
            }
            
            return response, audio_data, context
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration r√©ponse compl√®te: {e}")
            return "Erreur syst√®me", b"", {}

    async def get_next_speaker(self, last_speaker: str, context: str) -> str:
        """D√©termine le prochain agent √† parler"""
        agents_list = list(self.agents.keys())
        
        # Rotation intelligente
        if last_speaker == "michel_dubois_animateur":
            # Apr√®s Michel, alternance Sarah/Marcus
            return "sarah_johnson_journaliste" if "sarah" not in context.lower() else "marcus_thompson_expert"
        elif last_speaker == "sarah_johnson_journaliste":
            return "marcus_thompson_expert"
        else:
            return "michel_dubois_animateur"

    def log_performance_status(self):
        """Log le statut de performance du syst√®me"""
        logger.info("üìä STATUT PERFORMANCE ENHANCED MANAGER")
        logger.info(f"   Agents configur√©s: {len(self.agents)}")
        logger.info(f"   M√©moire conversation: {len(self.conversation_memory)} agents")
        logger.info(f"   Derni√®res r√©ponses: {len(self.last_responses)} agents")

    def get_performance_metrics(self) -> Dict:
        """Retourne les m√©triques de performance"""
        return {
            "introduction_ready": True,
            "cache_size": {agent_id: len(self.conversation_memory.get(agent_id, [])) for agent_id in self.agents.keys()},
            "total_agents": len(self.agents),
            "enhanced_manager": True
        }

    def set_last_speaker_message(self, speaker_type: str, message: str):
        """Enregistre le dernier message d'un type de speaker"""
        logger.info(f"üó£Ô∏è {speaker_type}: {message[:50]}...")

    async def process_agent_output(self, output: str, agent_id: str) -> Dict:
        """Traite la sortie d'un agent pour d√©tecter les interpellations"""
        # Simulation d'interpellations
        return {
            "triggered_responses": [
                {
                    "agent_id": "sarah_johnson_journaliste",
                    "content": "C'est int√©ressant, pouvez-vous pr√©ciser ?",
                    "reaction": "C'est int√©ressant, pouvez-vous pr√©ciser ?"
                }
            ]
        }

def get_enhanced_manager(openai_api_key: str, elevenlabs_api_key: str, 
                        config: MultiAgentConfig) -> EnhancedMultiAgentManager:
    """Factory function pour cr√©er le gestionnaire am√©lior√©"""
    return EnhancedMultiAgentManager(openai_api_key, elevenlabs_api_key, config)
