import asyncio
import logging
import json
import requests
import time
import numpy as np
from typing import Dict, List, Optional
from dataclasses import dataclass
from livekit import rtc, api
from livekit.agents import AutoSubscribe, JobContext, WorkerOptions, cli, llm
from livekit.agents.voice_assistant import VoiceAssistant
from livekit.plugins import openai, silero

@dataclass
class ConfidenceMetrics:
    """M√©triques de confiance en temps r√©el"""
    confidence_score: float = 0.0
    clarity_score: float = 0.0
    pace_score: float = 0.0
    energy_score: float = 0.0
    fluency_score: float = 0.0
    timestamp: float = 0.0

@dataclass
class ScenarioContext:
    """Contexte du sc√©nario Confidence Boost"""
    scenario_type: str = "interview"  # interview, presentation, negotiation
    difficulty: str = "facile"
    character_name: str = "Thomas"  # Thomas (recruteur), Marie (cliente)
    phase: str = "introduction"  # introduction, development, conclusion

class UnifiedConfidenceAgent:
    """Agent LiveKit unifi√© pour l'exercice Confidence Boost"""
    
    def __init__(self):
        self.room: Optional[rtc.Room] = None
        self.vosk_url = "http://localhost:8002"
        self.mistral_url = "http://localhost:8001"
        self.current_scenario: Optional[ScenarioContext] = None
        self.metrics_history: List[ConfidenceMetrics] = []
        self.conversation_context: List[str] = []
        self.session_start_time = time.time()
        
        # Configuration logging avanc√©
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger("UnifiedConfidenceAgent")
        
    async def initialize_scenario(self, scenario_data: Dict):
        """Initialise le contexte du sc√©nario"""
        self.current_scenario = ScenarioContext(
            scenario_type=scenario_data.get("type", "interview"),
            difficulty=scenario_data.get("difficulty", "facile"),
            character_name=scenario_data.get("character", "Thomas"),
            phase="introduction"
        )
        self.logger.info(f"Sc√©nario initialis√©: {self.current_scenario}")
        
    async def connect_to_room(self, room_name: str, token: str, scenario_data: Dict = None):
        """Connexion avanc√©e √† la room LiveKit avec configuration sc√©nario"""
        try:
            self.room = rtc.Room()
            
            # Initialiser le sc√©nario si fourni
            if scenario_data:
                await self.initialize_scenario(scenario_data)
            
            @self.room.on("participant_connected")
            def on_participant_connected(participant):
                self.logger.info(f"‚úÖ Participant connect√©: {participant.identity}")
                # Envoyer message de bienvenue adapt√© au sc√©nario
                asyncio.create_task(self.send_welcome_message())
                
            @self.room.on("participant_disconnected")
            def on_participant_disconnected(participant):
                self.logger.info(f"‚ùå Participant d√©connect√©: {participant.identity}")
                asyncio.create_task(self.finalize_session())
                
            @self.room.on("track_subscribed")
            def on_track_subscribed(track, publication, participant):
                if isinstance(track, rtc.AudioTrack):
                    self.logger.info(f"üé§ Track audio re√ßu de {participant.identity}")
                    asyncio.create_task(self.process_audio_stream(track, participant))
            
            # Connexion avec retry automatique
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    await self.room.connect("ws://localhost:7880", token)
                    self.logger.info(f"üöÄ Connect√© √† la room: {room_name}")
                    break
                except Exception as e:
                    if attempt < max_retries - 1:
                        self.logger.warning(f"Tentative {attempt + 1} √©chou√©e, retry: {e}")
                        await asyncio.sleep(2)
                    else:
                        raise e
                        
        except Exception as e:
            self.logger.error(f"‚ùå Erreur connexion LiveKit: {e}")
            raise
        
    async def process_audio_stream(self, audio_track, participant):
        """Pipeline unifi√© de traitement audio en temps r√©el"""
        frame_buffer = []
        buffer_duration = 0.5  # 500ms de buffer pour l'analyse
        
        async for frame in audio_track:
            try:
                frame_buffer.append(frame.data)
                
                # Traitement par chunks pour optimiser les performances
                if len(frame_buffer) >= int(buffer_duration * 16000 / 1024):  # ~8 frames √† 16kHz
                    # Combiner les frames audio
                    combined_audio = b''.join(frame_buffer)
                    frame_buffer.clear()
                    
                    # 1. Transcription en streaming
                    transcription = await self.transcribe_audio_streaming(combined_audio)
                    
                    if transcription.strip():
                        self.logger.info(f"üéØ Transcription: '{transcription}'")
                        self.conversation_context.append(f"USER: {transcription}")
                        
                        # 2. Analyse comportementale temps r√©el
                        metrics = await self.analyze_confidence_realtime(combined_audio, transcription)
                        self.metrics_history.append(metrics)
                        
                        # 3. Envoi m√©triques temps r√©el au client
                        await self.send_realtime_metrics(metrics)
                        
                        # 4. G√©n√©ration r√©ponse IA contextuelle (phrases compl√®tes)
                        if self.is_complete_sentence(transcription):
                            await self.handle_complete_sentence(transcription)
                            
                        # 5. Mise √† jour phase conversation
                        await self.update_conversation_phase()
                
            except Exception as e:
                self.logger.error(f"‚ùå Erreur traitement audio: {e}")
                continue
                
    async def handle_complete_sentence(self, transcription: str):
        """G√®re une phrase compl√®te de l'utilisateur"""
        try:
            # G√©n√©rer r√©ponse IA adapt√©e au sc√©nario
            ai_response = await self.generate_contextual_ai_response(transcription)
            
            if ai_response:
                self.conversation_context.append(f"AI: {ai_response}")
                self.logger.info(f"ü§ñ R√©ponse IA: '{ai_response}'")
                
                # Synth√®se vocale et envoi audio
                ai_audio = await self.synthesize_speech(ai_response)
                await self.send_ai_audio_to_room(ai_audio)
                
                # Envoi transcription pour l'interface
                await self.send_conversation_update(transcription, ai_response)
                
        except Exception as e:
            self.logger.error(f"‚ùå Erreur g√©n√©ration r√©ponse: {e}")
    
    async def transcribe_audio_streaming(self, audio_data: bytes) -> str:
        """Transcription en streaming optimis√©e via Vosk"""
        try:
            # Envoi optimis√© avec timeout
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    requests.post,
                    f"{self.vosk_url}/transcribe",
                    data=audio_data,
                    headers={"Content-Type": "audio/wav"}
                ),
                timeout=2.0
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get("text", "").strip()
            else:
                self.logger.warning(f"Vosk erreur HTTP {response.status_code}")
                return ""
                
        except asyncio.TimeoutError:
            self.logger.warning("Timeout transcription Vosk")
            return ""
        except Exception as e:
            self.logger.error(f"Erreur transcription: {e}")
            return ""
    
    async def analyze_confidence_realtime(self, audio_data: bytes, transcription: str) -> ConfidenceMetrics:
        """Analyse comportementale avanc√©e temps r√©el"""
        try:
            # Analyse audio (volume, d√©bit, pauses)
            audio_features = await self.extract_audio_features(audio_data)
            
            # Analyse textuelle (h√©sitations, mots de remplissage)
            text_features = self.analyze_text_features(transcription)
            
            # Calcul scores composites
            confidence_score = self.calculate_confidence_score(audio_features, text_features)
            clarity_score = self.calculate_clarity_score(audio_features, text_features)
            pace_score = self.calculate_pace_score(audio_features)
            energy_score = self.calculate_energy_score(audio_features)
            fluency_score = self.calculate_fluency_score(text_features)
            
            metrics = ConfidenceMetrics(
                confidence_score=confidence_score,
                clarity_score=clarity_score,
                pace_score=pace_score,
                energy_score=energy_score,
                fluency_score=fluency_score,
                timestamp=time.time() - self.session_start_time
            )
            
            return metrics
            
        except Exception as e:
            self.logger.error(f"Erreur analyse confiance: {e}")
            return ConfidenceMetrics(timestamp=time.time() - self.session_start_time)
    
    async def generate_contextual_ai_response(self, transcription: str) -> str:
        """G√©n√©ration r√©ponse IA contextuelle selon le sc√©nario"""
        try:
            # Construction du prompt contextuel
            context_prompt = self.build_scenario_prompt(transcription)
            
            # Appel service Mistral avec contexte
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    requests.post,
                    f"{self.mistral_url}/generate",
                    json={
                        "prompt": context_prompt,
                        "max_tokens": 150,
                        "temperature": 0.7,
                        "scenario": self.current_scenario.__dict__ if self.current_scenario else {}
                    }
                ),
                timeout=5.0
            )
            
            if response.status_code == 200:
                result = response.json()
                ai_text = result.get("response", "").strip()
                
                # Filtrer les r√©ponses inappropri√©es
                if self.is_appropriate_response(ai_text):
                    return ai_text
                else:
                    return self.get_fallback_response()
            else:
                return self.get_fallback_response()
                
        except Exception as e:
            self.logger.error(f"Erreur g√©n√©ration IA: {e}")
            return self.get_fallback_response()
    
    def build_scenario_prompt(self, user_input: str) -> str:
        """Construit le prompt contextuel selon le sc√©nario"""
        if not self.current_scenario:
            return f"R√©pondez naturellement √†: {user_input}"
            
        character_prompts = {
            "Thomas": f"""Tu es Thomas, un recruteur bienveillant mais exigeant.
                         Contexte: entretien d'embauche de niveau {self.current_scenario.difficulty}.
                         Le candidat dit: "{user_input}"
                         R√©ponds comme un recruteur professionnel, pose des questions pertinentes.""",
            
            "Marie": f"""Tu es Marie, une cliente int√©ress√©e mais critique.
                        Contexte: pr√©sentation de niveau {self.current_scenario.difficulty}.
                        Le pr√©sentateur dit: "{user_input}"
                        R√©ponds comme une cliente exigeante, demande des pr√©cisions."""
        }
        
        return character_prompts.get(
            self.current_scenario.character_name,
            f"R√©pondez professionnellement √†: {user_input}"
        )
    
    # === M√âTHODES D'ANALYSE AUDIO AVANC√âES ===
    
    async def extract_audio_features(self, audio_data: bytes) -> Dict:
        """Extraction features audio basiques"""
        try:
            # Simulation d'analyse audio (√† remplacer par librairie audio r√©elle)
            volume = len(audio_data) / 1000.0  # Approximation volume
            return {
                "volume": min(volume, 1.0),
                "duration": len(audio_data) / 16000.0,  # Estimation dur√©e
                "silence_ratio": 0.1,  # √Ä calculer r√©ellement
                "pace": 1.0  # Mots par seconde estim√©
            }
        except:
            return {"volume": 0.5, "duration": 0.5, "silence_ratio": 0.2, "pace": 1.0}
    
    def analyze_text_features(self, text: str) -> Dict:
        """Analyse features textuelles"""
        hesitations = len([w for w in text.lower().split() if w in ["euh", "hm", "ben", "donc", "en fait"]])
        word_count = len(text.split())
        
        return {
            "hesitation_count": hesitations,
            "word_count": word_count,
            "hesitation_ratio": hesitations / max(word_count, 1),
            "sentence_length": word_count
        }
    
    def calculate_confidence_score(self, audio_features: Dict, text_features: Dict) -> float:
        """Calcul score de confiance composite"""
        # Score bas√© sur volume, h√©sitations, d√©bit
        volume_score = min(audio_features["volume"] * 2, 1.0)
        hesitation_penalty = text_features["hesitation_ratio"] * 0.5
        pace_score = min(audio_features["pace"], 1.0)
        
        final_score = (volume_score + pace_score) / 2 - hesitation_penalty
        return max(0.0, min(1.0, final_score))
    
    def calculate_clarity_score(self, audio_features: Dict, text_features: Dict) -> float:
        """Score de clart√©"""
        return max(0.3, min(1.0, 1.0 - text_features["hesitation_ratio"]))
    
    def calculate_pace_score(self, audio_features: Dict) -> float:
        """Score de d√©bit"""
        ideal_pace = 1.5  # mots/seconde id√©al
        pace_diff = abs(audio_features["pace"] - ideal_pace)
        return max(0.2, 1.0 - pace_diff)
    
    def calculate_energy_score(self, audio_features: Dict) -> float:
        """Score d'√©nergie"""
        return min(1.0, audio_features["volume"] * 1.2)
    
    def calculate_fluency_score(self, text_features: Dict) -> float:
        """Score de fluidit√©"""
        return max(0.1, 1.0 - text_features["hesitation_ratio"] * 2)
    
    # === M√âTHODES DE COMMUNICATION ===
    
    async def send_realtime_metrics(self, metrics: ConfidenceMetrics):
        """Envoi m√©triques temps r√©el au client"""
        try:
            if self.room:
                metrics_data = {
                    "type": "confidence_metrics",
                    "data": {
                        "confidence": metrics.confidence_score,
                        "clarity": metrics.clarity_score,
                        "pace": metrics.pace_score,
                        "energy": metrics.energy_score,
                        "fluency": metrics.fluency_score,
                        "timestamp": metrics.timestamp
                    }
                }
                
                # Envoi via DataChannel LiveKit
                await self.room.local_participant.publish_data(
                    json.dumps(metrics_data).encode(),
                    reliable=True
                )
                
        except Exception as e:
            self.logger.error(f"Erreur envoi m√©triques: {e}")
    
    async def send_conversation_update(self, user_text: str, ai_response: str):
        """Envoi mise √† jour conversation"""
        try:
            if self.room:
                conversation_data = {
                    "type": "conversation_update",
                    "data": {
                        "user_message": user_text,
                        "ai_response": ai_response,
                        "timestamp": time.time(),
                        "character": self.current_scenario.character_name if self.current_scenario else "AI"
                    }
                }
                
                await self.room.local_participant.publish_data(
                    json.dumps(conversation_data).encode(),
                    reliable=True
                )
                
        except Exception as e:
            self.logger.error(f"Erreur envoi conversation: {e}")
    
    async def send_welcome_message(self):
        """Envoie message de bienvenue adapt√© au sc√©nario"""
        if not self.current_scenario:
            return
            
        welcome_messages = {
            "Thomas": "Bonjour ! Je suis Thomas, votre recruteur. Pr√©sentez-vous et expliquez-moi pourquoi vous souhaitez rejoindre notre √©quipe.",
            "Marie": "Bonjour ! Je suis Marie, votre cliente. Je suis curieuse de d√©couvrir votre pr√©sentation. Commencez quand vous √™tes pr√™t !"
        }
        
        welcome_text = welcome_messages.get(
            self.current_scenario.character_name,
            "Bonjour ! Commen√ßons cet exercice ensemble."
        )
        
        # Envoi message de bienvenue
        await self.send_conversation_update("", welcome_text)
        
        # Synth√®se vocale du message de bienvenue
        welcome_audio = await self.synthesize_speech(welcome_text)
        await self.send_ai_audio_to_room(welcome_audio)
    
    async def synthesize_speech(self, text: str) -> bytes:
        """Synth√®se vocale du texte"""
        try:
            # TODO: Int√©grer service TTS r√©el (Azure, Google, etc.)
            # Pour l'instant, retourne donn√©es audio simul√©es
            self.logger.info(f"üîä Synth√®se: '{text[:50]}...'")
            return b"audio_data_placeholder"
        except Exception as e:
            self.logger.error(f"Erreur synth√®se vocale: {e}")
            return b""
    
    async def send_ai_audio_to_room(self, audio_data: bytes):
        """Envoi audio IA dans la room"""
        try:
            if self.room and audio_data:
                # TODO: Cr√©er track audio et publier
                # audio_source = rtc.AudioSource(sample_rate=16000, num_channels=1)
                # track = rtc.LocalAudioTrack.create_audio_track("ai-voice", audio_source)
                # await self.room.local_participant.publish_track(track)
                self.logger.info("üîä Audio IA envoy√©")
        except Exception as e:
            self.logger.error(f"Erreur envoi audio: {e}")
    
    # === M√âTHODES UTILITAIRES ===
    
    def is_complete_sentence(self, text: str) -> bool:
        """D√©tecte si la phrase est compl√®te"""
        text = text.strip()
        return (len(text) > 5 and
                (text.endswith(('.', '!', '?')) or
                 len(text.split()) >= 4))  # ou phrase de 4+ mots
    
    def is_appropriate_response(self, response: str) -> bool:
        """V√©rifie si la r√©ponse IA est appropri√©e"""
        inappropriate_keywords = ["inappropri√©", "offensant", "erreur"]
        return not any(keyword in response.lower() for keyword in inappropriate_keywords)
    
    def get_fallback_response(self) -> str:
        """R√©ponse de fallback selon le sc√©nario"""
        if not self.current_scenario:
            return "Je vous √©coute, continuez..."
            
        fallback_responses = {
            "Thomas": "Tr√®s int√©ressant. Pouvez-vous me donner plus de d√©tails ?",
            "Marie": "C'est un bon point. Comment comptez-vous concr√®tement proc√©der ?"
        }
        
        return fallback_responses.get(
            self.current_scenario.character_name,
            "Je vous √©coute, continuez..."
        )
    
    async def update_conversation_phase(self):
        """Met √† jour la phase de conversation"""
        if not self.current_scenario:
            return
            
        conversation_length = len(self.conversation_context)
        
        if conversation_length <= 4:
            self.current_scenario.phase = "introduction"
        elif conversation_length <= 12:
            self.current_scenario.phase = "development"
        else:
            self.current_scenario.phase = "conclusion"
    
    async def finalize_session(self):
        """Finalise la session et g√©n√®re le rapport"""
        try:
            session_duration = time.time() - self.session_start_time
            
            # Calcul scores finaux
            avg_metrics = self.calculate_average_metrics()
            
            # G√©n√©ration rapport final
            final_report = {
                "type": "session_complete",
                "data": {
                    "duration": session_duration,
                    "metrics": avg_metrics,
                    "conversation_length": len(self.conversation_context),
                    "scenario": self.current_scenario.__dict__ if self.current_scenario else {},
                    "timestamp": time.time()
                }
            }
            
            if self.room:
                await self.room.local_participant.publish_data(
                    json.dumps(final_report).encode(),
                    reliable=True
                )
                
            self.logger.info(f"‚úÖ Session finalis√©e: {session_duration:.1f}s")
            
        except Exception as e:
            self.logger.error(f"Erreur finalisation: {e}")
    
    def calculate_average_metrics(self) -> Dict:
        """Calcule les m√©triques moyennes de la session"""
        if not self.metrics_history:
            return {"confidence": 0.5, "clarity": 0.5, "pace": 0.5, "energy": 0.5, "fluency": 0.5}
        
        avg_confidence = sum(m.confidence_score for m in self.metrics_history) / len(self.metrics_history)
        avg_clarity = sum(m.clarity_score for m in self.metrics_history) / len(self.metrics_history)
        avg_pace = sum(m.pace_score for m in self.metrics_history) / len(self.metrics_history)
        avg_energy = sum(m.energy_score for m in self.metrics_history) / len(self.metrics_history)
        avg_fluency = sum(m.fluency_score for m in self.metrics_history) / len(self.metrics_history)
        
        return {
            "confidence": round(avg_confidence, 2),
            "clarity": round(avg_clarity, 2),
            "pace": round(avg_pace, 2),
            "energy": round(avg_energy, 2),
            "fluency": round(avg_fluency, 2)
        }

# === POINT D'ENTR√âE PRINCIPAL ===

async def main():
    """Point d'entr√©e principal de l'agent unifi√©"""
    import os
    
    # Configuration depuis variables d'environnement
    room_name = os.getenv("LIVEKIT_ROOM", "confidence-boost")
    livekit_url = os.getenv("LIVEKIT_URL", "ws://localhost:7880")
    livekit_token = os.getenv("LIVEKIT_TOKEN", "token-placeholder")
    
    # Sc√©nario par d√©faut (peut √™tre overrid√© par l'API)
    default_scenario = {
        "type": "interview",
        "difficulty": "facile",
        "character": "Thomas"
    }
    
    print("üöÄ D√©marrage UnifiedConfidenceAgent...")
    print(f"   Room: {room_name}")
    print(f"   URL LiveKit: {livekit_url}")
    print(f"   Sc√©nario: {default_scenario}")
    
    try:
        # Initialisation agent
        agent = UnifiedConfidenceAgent()
        
        # Connexion √† la room avec sc√©nario
        await agent.connect_to_room(room_name, livekit_token, default_scenario)
        
        print("‚úÖ Agent connect√© avec succ√®s !")
        print("üéØ En attente des participants...")
        
        # Maintenir la connexion active
        while True:
            await asyncio.sleep(1)
            
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Arr√™t de l'agent...")
    except Exception as e:
        print(f"‚ùå Erreur critique: {e}")
        raise

if __name__ == "__main__":
    # Configuration logging pour production
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('/tmp/livekit-agent.log') if os.path.exists('/tmp') else logging.NullHandler()
        ]
    )
    
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nüëã Au revoir !")
    except Exception as e:
        print(f"üí• Erreur fatale: {e}")
        exit(1)
