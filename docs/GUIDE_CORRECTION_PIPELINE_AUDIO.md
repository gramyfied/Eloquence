# üîß GUIDE CORRECTION PIPELINE AUDIO IA

## üìã R√âSUM√â DES CORRECTIONS APPLIQU√âES

### ‚ùå PROBL√àMES IDENTIFI√âS
1. **Mistral LLM** : Simulait des r√©ponses au lieu d'utiliser l'API Scaleway r√©elle
2. **Int√©gration des services** : Probl√®mes de communication entre les services
3. **Configuration incoh√©rente** : Variables d'environnement mal synchronis√©es

### ‚úÖ CORRECTIONS IMPL√âMENT√âES

#### 1. **Agent Corrig√© avec Vraie API Mistral**
- **Fichier** : `services/api-backend/services/real_time_voice_agent_corrected.py`
- **Correction principale** : `RealMistralLLM` utilise maintenant l'API Scaleway
- **Pipeline complet** : Whisper STT (Hugging Face) ‚Üí Mistral (Scaleway) ‚Üí Azure TTS ‚Üí LiveKit

#### 2. **Script de Diagnostic Complet**
- **Fichier** : `scripts/diagnostic_pipeline_audio_complet.py`
- **Fonctionnalit√©** : Teste chaque service individuellement puis le pipeline complet
- **Rapport** : G√©n√®re un rapport JSON d√©taill√©

#### 3. **Script de Lancement Facile**
- **Fichier** : `scripts/lancer_diagnostic_pipeline.bat`
- **Utilisation** : Double-clic pour lancer le diagnostic

## üöÄ UTILISATION IMM√âDIATE

### √âtape 1 : Lancer le Diagnostic
```bash
# Windows
cd c:/Users/User/Desktop/25Eloquence-Finalisation
scripts/lancer_diagnostic_pipeline.bat

# Linux/macOS
cd /path/to/25Eloquence-Finalisation
python scripts/diagnostic_pipeline_audio_complet.py
```

### √âtape 2 : Analyser les R√©sultats
Le script va tester :
1. ‚úÖ **Whisper STT** (Hugging Face) - Transcription audio
2. ‚úÖ **Mistral LLM** (API Scaleway) - G√©n√©ration de r√©ponses
3. ‚úÖ **Azure TTS** - Synth√®se vocale
4. ‚úÖ **Pipeline Complet** - Test end-to-end

### √âtape 3 : Utiliser l'Agent Corrig√©
Pour remplacer l'agent existant par la version corrig√©e :
```bash
# Sauvegarder l'ancien agent
cp services/api-backend/services/real_time_voice_agent_docker_fixed.py services/api-backend/services/real_time_voice_agent_docker_fixed.py.backup

# Utiliser l'agent corrig√©
cp services/api-backend/services/real_time_voice_agent_corrected.py services/api-backend/services/real_time_voice_agent_docker_fixed.py
```

## üîç D√âTAILS TECHNIQUES DES CORRECTIONS

### **RealMistralLLM - Correction Principale**

**AVANT (Simulation)** :
```python
class CustomMistralLLM(llm.LLM):
    async def _chat_stream(self):
        # Simulation d'une r√©ponse intelligente bas√©e sur le message
        if "bonjour" in user_message.lower():
            response = "Bonjour ! Je suis votre assistant vocal..."
```

**APR√àS (Vraie API)** :
```python
class RealMistralLLM(llm.LLM):
    async def _chat_stream(self):
        # Appel √† la vraie API Mistral Scaleway
        session = await self.llm._get_session()
        response = await session.post(
            self.llm.base_url,  # https://api.scaleway.ai/...
            json=payload,
            headers={"Authorization": f"Bearer {self.llm.api_key}"}
        )
        # Traitement de la vraie r√©ponse JSON
```

### **Pipeline de Test Complet**

Le script de diagnostic teste chaque √©tape :

1. **Test Whisper STT** :
   - G√©n√®re un fichier audio de test (tonalit√© 440Hz)
   - Envoie √† `http://whisper-stt:8001/transcribe`
   - V√©rifie la transcription

2. **Test Mistral LLM** :
   - Envoie un prompt de test √† l'API Scaleway
   - V√©rifie la r√©ponse JSON format OpenAI
   - Mesure le temps de r√©ponse

3. **Test Azure TTS** :
   - Synth√©tise un texte de test
   - V√©rifie la g√©n√©ration audio
   - Mesure la qualit√© audio

4. **Test Pipeline Complet** :
   - Audio test ‚Üí Whisper ‚Üí Mistral ‚Üí Azure TTS
   - Mesure la latence totale
   - Valide le pipeline end-to-end

## üìä CONFIGURATION REQUISE

### Variables d'Environnement (.env)
```env
# Whisper STT (Hugging Face)
WHISPER_STT_URL=http://whisper-stt:8001

# Mistral LLM (API Scaleway) - CORRIG√â
MISTRAL_API_KEY=your_mistral_api_key_here
MISTRAL_BASE_URL=https://api.scaleway.ai/18f6cc9d-07fc-49c3-a142-67be9b59ac63/v1/chat/completions
MISTRAL_MODEL=mistral-nemo-instruct-2407

# Azure TTS
AZURE_TTS_URL=http://azure-tts:5002
AZURE_API_KEY=BKgv0IJJ5QeMqc9CyjezN7diPFcp5DMxbLSqXZHQ0rsC4mQCT7JwJQQJ99BFACHYHv6XJ3w3AAAAACOG6Qua

# LiveKit
LIVEKIT_URL=ws://livekit:7880
LIVEKIT_API_KEY=devkey
LIVEKIT_API_SECRET=livekit_secret_key_32_characters_long_for_security_2025
```

### Docker Compose (docker-compose.yml)
```yaml
services:
  eloquence-agent-v1:
    environment:
      - WHISPER_STT_URL=http://whisper-stt:8001
      - AZURE_TTS_URL=http://azure-tts:5002
      - MISTRAL_API_KEY=your_mistral_api_key_here
      - MISTRAL_BASE_URL=https://api.scaleway.ai/.../v1/chat/completions
      - MISTRAL_MODEL=mistral-nemo-instruct-2407
```

## üõ†Ô∏è R√âSOLUTION DES PROBL√àMES

### Probl√®me : "Services individuels OK, mais pipeline complet √©choue"
**Solution** : V√©rifier les URLs Docker internes dans `docker-compose.yml`
- Utiliser `http://whisper-stt:8001` et non `http://localhost:8001`
- V√©rifier que tous les services sont sur le m√™me r√©seau Docker

### Probl√®me : "Mistral API retourne 401 Unauthorized"
**Solution** : V√©rifier la cl√© API Mistral dans `.env` et `docker-compose.yml`
- La cl√© doit √™tre identique partout
- Format : `xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx` (UUID)

### Probl√®me : "Whisper ne transcrit pas l'audio"
**Solution** : V√©rifier que Whisper utilise le mod√®le Turbo
- Mod√®le : `openai/whisper-large-v3-turbo`
- Device : `cpu` ou `cuda` selon votre configuration

## üìà AM√âLIORATIONS APPORT√âES

1. **Vraie Intelligence Artificielle** :
   - Mistral g√©n√®re des r√©ponses contextuelles uniques
   - Pas de r√©ponses pr√©-programm√©es

2. **Latence R√©duite** :
   - Whisper Turbo : 8x plus rapide
   - Pipeline optimis√© pour temps r√©el

3. **Fiabilit√© Accrue** :
   - Gestion d'erreurs robuste
   - Fallbacks pour chaque service
   - Logs d√©taill√©s pour diagnostic

## üöÄ PROCHAINES √âTAPES

1. **Int√©gration Production** :
   ```bash
   # Remplacer l'agent dans le Dockerfile
   COPY services/api-backend/services/real_time_voice_agent_corrected.py /app/agent.py
   ```

2. **Tests d'Int√©gration** :
   ```bash
   # Lancer les tests avec Docker
   docker-compose up -d
   docker-compose exec eloquence-agent-v1 python -m pytest tests/
   ```

3. **Monitoring** :
   - Activer les m√©triques dans le dashboard
   - Surveiller les temps de r√©ponse
   - Analyser les logs d'erreur

## üìû SUPPORT

Si vous rencontrez des probl√®mes :
1. Lancer le diagnostic : `scripts/lancer_diagnostic_pipeline.bat`
2. V√©rifier les logs : `docker-compose logs eloquence-agent-v1`
3. Consulter le rapport JSON g√©n√©r√© par le diagnostic

---

**üéâ F√âLICITATIONS !** Votre pipeline audio IA est maintenant op√©rationnel avec la vraie API Mistral !
