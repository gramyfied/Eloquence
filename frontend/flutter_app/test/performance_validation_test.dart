import 'package:flutter_test/flutter_test.dart';
import 'package:eloquence_2_0/features/confidence_boost/data/services/mistral_cache_service.dart';
import 'package:eloquence_2_0/features/confidence_boost/data/services/whisper_streaming_service.dart';
import 'package:eloquence_2_0/core/services/optimized_http_service.dart';
import 'package:eloquence_2_0/core/utils/logger_service.dart';
import 'package:eloquence_2_0/features/confidence_boost/domain/entities/confidence_scenario.dart';
import 'package:eloquence_2_0/features/confidence_boost/domain/entities/confidence_models.dart';
import 'dart:typed_data';
import 'package:flutter_dotenv/flutter_dotenv.dart';
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:eloquence_2_0/features/confidence_boost/presentation/providers/mistral_api_service_provider.dart';
import 'fakes/fake_mistral_api_service.dart';

/// Tests de validation des performances apr√®s optimisations
///
/// Objectifs :
/// - Latence totale < 3 secondes
/// - Cache Mistral < 100ms pour les hits
/// - Streaming Whisper < 2s par chunk
/// - Pool de connexions HTTP fonctionnel
void main() {
  setUpAll(() async {
    // Charger les variables d'environnement pour les tests
    await dotenv.load(fileName: '.env');
  });

  group('üöÄ Tests de validation des performances mobile', () {
    
    late ProviderContainer container;
    late FakeMistralApiService fakeService;

    setUp(() {
      fakeService = FakeMistralApiService();
      container = ProviderContainer();
    });

    tearDown(() {
      container.dispose();
    });

    // === Test 1 : Cache Mistral Performance ===
    test('Cache Mistral doit r√©pondre en < 100ms pour les hits', () async {
      logger.i('TEST', 'üß™ Test performance cache Mistral');
      logger.i('TEST', 'MISTRAL_ENABLED: ${dotenv.env['MISTRAL_ENABLED']}');
      logger.i('TEST', 'LLM_SERVICE_URL: ${dotenv.env['LLM_SERVICE_URL']}');
      const prompt = 'Test de performance cache : G√©n√®re un feedback motivant';
      
      // Premier appel : miss de cache (non mesur√©)
      await container.read(mistralApiServiceProvider).generateText(
        prompt: prompt,
        maxTokens: 100,
        temperature: 0.7,
      );
      
      // Deuxi√®me appel : hit de cache (mesur√©)
      final stopwatch = Stopwatch()..start();
      
      final cachedResult = await container.read(mistralApiServiceProvider).generateText(
        prompt: prompt,
        maxTokens: 100,
        temperature: 0.7,
      );
      
      stopwatch.stop();
      final cacheLatency = stopwatch.elapsedMilliseconds;
      
      logger.i('TEST', '‚è±Ô∏è Latence cache Mistral: ${cacheLatency}ms');
      
      // V√©rification
      expect(cachedResult, isNotNull);
      expect(cachedResult, isNotEmpty);
      expect(cacheLatency, lessThan(100),
        reason: 'Le cache doit r√©pondre en moins de 100ms'
      );
      
      // V√©rifier les statistiques du cache
      final stats = MistralCacheService.getStatistics();
      if (stats['hitRate'] != null) {
        expect(stats['hitRate'], isA<num>(), reason: 'Le hit rate doit √™tre un nombre');
        expect(stats['hitRate'], greaterThanOrEqualTo(0), reason: 'Le hit rate doit √™tre >= 0 apr√®s un hit');
      } else {
        logger.w('TEST', 'hitRate est null : le backend ne fournit pas cette statistique dans ce mode.');
      }
    });
    
    // === Test 2 : Performance streaming Whisper ===
    test('Streaming Whisper doit traiter les chunks en < 2s', () async {
      logger.i('TEST', 'üß™ Test performance streaming Whisper');
      
      final whisperService = WhisperStreamingService();
      final scenario = ConfidenceScenario(
        id: 'test-scenario',
        title: 'Sc√©nario de test',
        description: 'Test de performance',
        prompt: 'Testez votre capacit√© de streaming',
        type: ConfidenceScenarioType.presentation,
        durationSeconds: 30,
        tips: ['Restez naturel', 'Parlez clairement'],
        keywords: ['test', 'performance'],
        difficulty: 'beginner',
        icon: 'üéØ',
      );
      
      // D√©marrer la session
      final sessionStarted = await whisperService.startStreamingSession(
        scenario: scenario,
        language: 'fr',
      );
      
      expect(sessionStarted, isTrue);
      
      // Simuler l'envoi d'un chunk audio
      final testAudioData = Uint8List(320000); // ~10s d'audio √† 16kHz
      
      final stopwatch = Stopwatch()..start();
      
      // √âcouter la transcription
      bool transcriptionReceived = false;
      whisperService.transcriptionStream.listen((text) {
        if (text.isNotEmpty) {
          transcriptionReceived = true;
          logger.i('TEST', 'üìù Transcription partielle re√ßue: ${text.length} caract√®res');
        }
      });
      
      // Ajouter les donn√©es audio
      await whisperService.addAudioData(testAudioData);
      
      // Attendre max 2 secondes pour la transcription
      await Future.delayed(Duration(seconds: 2));
      
      stopwatch.stop();
      final chunkLatency = stopwatch.elapsedMilliseconds;
      
      logger.i('TEST', '‚è±Ô∏è Latence chunk Whisper: ${chunkLatency}ms');
      
      // Nettoyage
      await whisperService.stopStreaming();
      whisperService.dispose();
      
      // V√©rifications
      expect(chunkLatency, lessThan(2000), 
        reason: 'Le chunk doit √™tre trait√© en moins de 2s'
      );
    });
    
    // === Test 3 : Performance HTTP optimis√© ===
    test('Service HTTP optimis√© doit utiliser le pool de connexions', () async {
      logger.i('TEST', 'üß™ Test performance HTTP optimis√©');
      
      final httpService = OptimizedHttpService();
      
      // Test multiple requ√™tes pour v√©rifier le pool
      final urls = [
        'https://httpbin.org/delay/0',
        'https://httpbin.org/delay/0',
        'https://httpbin.org/delay/0',
      ];
      
      final stopwatch = Stopwatch()..start();
      
      // Ex√©cuter 3 requ√™tes en parall√®le
      final futures = urls.map((url) => 
        httpService.get(url, timeout: Duration(seconds: 5))
      ).toList();
      
      final responses = await Future.wait(futures);
      
      stopwatch.stop();
      final totalLatency = stopwatch.elapsedMilliseconds;
      
      logger.i('TEST', '‚è±Ô∏è Latence totale 3 requ√™tes: ${totalLatency}ms');
      
      // V√©rifications
      expect(responses.length, equals(3));
      for (final response in responses) {
        expect(response.statusCode, equals(200));
      }
      
      // Avec le pool, les 3 requ√™tes devraient prendre moins qu'en s√©quentiel
      // Note: Sur certaines connexions r√©seau, cela peut prendre plus de temps
      expect(totalLatency, lessThan(3000),
        reason: 'Le pool de connexions doit am√©liorer les performances'
      );
    });
    
    // === Test 4 : Latence end-to-end < 3s ===
    test('Latence end-to-end doit √™tre < 3s', () async {
      logger.i('TEST', 'üß™ Test latence end-to-end compl√®te');
      
      final stopwatch = Stopwatch()..start();
      
      // Simuler un workflow complet
      try {
        // 1. G√©n√©ration de texte avec Mistral (avec cache)
        final mistralText = await container.read(mistralApiServiceProvider).generateText(
          prompt: 'Tu es un coach motivant. G√©n√®re un encouragement court pour quelqu\'un qui pratique la prise de parole.',
          maxTokens: 50,
          temperature: 0.7,
        );
        
        final mistralTime = stopwatch.elapsedMilliseconds;
        logger.i('TEST', '‚è±Ô∏è Mistral: ${mistralTime}ms');
        
        // 2. Analyse avec Mistral (utilise aussi HTTP optimis√©)
        // On teste analyzeContent qui existe dans MistralApiService
        try {
          final analysisResult = await container.read(mistralApiServiceProvider).analyzeContent(
            prompt: 'Analyse cette pr√©sentation : "Je suis heureux de vous pr√©senter notre projet"',
            maxTokens: 200,
          ).timeout(Duration(seconds: 2));
          
          logger.d('TEST', 'Analyse re√ßue: ${analysisResult['feedback']}');
        } catch (e) {
          // Attendu en test si l'API n'est pas disponible
          logger.w('TEST', 'API non disponible (normal en test)');
        }
        
        final analysisTime = stopwatch.elapsedMilliseconds - mistralTime;
        logger.i('TEST', '‚è±Ô∏è Analyse: ${analysisTime}ms');
        
        stopwatch.stop();
        final totalTime = stopwatch.elapsedMilliseconds;
        
        logger.i('TEST', '‚è±Ô∏è LATENCE TOTALE: ${totalTime}ms');
        
        // V√©rification finale
        expect(totalTime, lessThan(3000), 
          reason: 'La latence totale doit √™tre < 3 secondes'
        );
        
      } catch (e) {
        logger.e('TEST', 'Erreur test end-to-end: $e');
        // En cas d'erreur r√©seau, on v√©rifie au moins que le timeout fonctionne
        stopwatch.stop();
        expect(stopwatch.elapsedMilliseconds, lessThan(3000));
      }
    });
    
    // === Test 5 : V√©rification des fallbacks ===
    test('Les fallbacks doivent fonctionner en cas d\'erreur', () async {
      logger.i('TEST', 'üß™ Test robustesse des fallbacks');
      
      // Test avec une URL invalide
      final httpService = OptimizedHttpService();
      
      try {
        // Cette requ√™te devrait √©chouer mais avec retry logic
        final response = await httpService.get(
          'http://invalid-url-that-does-not-exist.test',
          timeout: Duration(seconds: 2),
          maxRetries: 2,
        );
        
        // Si on arrive ici, le fallback n'a pas fonctionn√©
        fail('La requ√™te aurait d√ª √©chouer');
        
      } catch (e) {
        // Succ√®s : l'erreur est g√©r√©e proprement
        logger.i('TEST', '‚úÖ Fallback fonctionnel: $e');
        // L'erreur peut √™tre soit "Failed after" soit "Failed host lookup"
        expect(
          e.toString().contains('Failed after') ||
          e.toString().contains('Failed host lookup'),
          isTrue,
          reason: 'L\'erreur doit √™tre g√©r√©e correctement'
        );
      }
    });
    
    // === Test 6 : Statistiques du cache ===
    test('Le cache doit fournir des statistiques pr√©cises', () async {
      logger.i('TEST', 'üß™ Test statistiques du cache');
      
      // R√©initialiser le cache
      await MistralCacheService.clearCache();
      
      // Faire quelques requ√™tes
      await container.read(mistralApiServiceProvider).generateText(
        prompt: 'Test 1 : G√©n√®re un feedback constructif',
        maxTokens: 50,
      );
      
      await container.read(mistralApiServiceProvider).generateText(
        prompt: 'Test 2 : Donne des conseils de pr√©sentation',
        maxTokens: 50,
      );
      
      // R√©p√©ter une requ√™te (hit)
      await container.read(mistralApiServiceProvider).generateText(
        prompt: 'Test 1 : G√©n√®re un feedback constructif',
        maxTokens: 50,
      );
      
      // V√©rifier les statistiques
      final stats = MistralCacheService.getStatistics();
      
      logger.i('TEST', 'üìä Statistiques cache: $stats');
      
      expect(stats['totalRequests'], equals(3));
      expect(stats['cacheHits'], equals(1));
      expect(stats['cacheMisses'], equals(2));
      expect(stats['hitRate'], closeTo(0.33, 0.01));
      expect(stats['memoryEntries'], equals(2));
    });
  });
}