import 'dart:async';
import 'dart:convert';
import 'dart:math' as math;
import 'package:logger/logger.dart';
import 'package:flutter_dotenv/flutter_dotenv.dart';
import '../../../../core/services/optimized_http_service.dart';
import '../../../../core/config/app_config.dart';
import '../../domain/entities/confidence_scenario.dart';
import '../../domain/entities/confidence_models.dart';
import '../../domain/entities/ai_character_models.dart';
import 'adaptive_ai_character_service.dart';

/// Moteur de conversation avec Mistral pour la g√©n√©ration de r√©ponses IA adaptatives
/// 
/// ‚úÖ FONCTIONNALIT√âS :
/// - G√©n√©ration de r√©ponses contextuelles avec Mistral
/// - Personnages IA diff√©rents selon le sc√©nario
/// - Gestion de l'historique de conversation
/// - Adaptation dynamique selon les performances
/// - Support multi-tours de conversation
class ConversationEngine {
  static const String _tag = 'ConversationEngine';
  final Logger _logger = Logger();
  
  // Services
  final OptimizedHttpService _httpService;
  final AdaptiveAICharacterService _aiCharacterService;
  
  // Constructeur avec injection de d√©pendances pour les tests
  ConversationEngine({
    OptimizedHttpService? httpService,
    AdaptiveAICharacterService? aiCharacterService,
  }) : _httpService = httpService ?? OptimizedHttpService(),
        _aiCharacterService = aiCharacterService ?? AdaptiveAICharacterService();
  
  // Configuration Mistral
  static String get _mistralBaseUrl => AppConfig.mistralBaseUrl;
  static String get _mistralApiKey => dotenv.env['MISTRAL_API_KEY'] ?? '';
  static const String _mistralModel = 'mistral-medium-latest'; // Mod√®le optimis√© pour la conversation
  
  // √âtat de la conversation
  final List<ConversationTurn> _conversationHistory = [];
  AICharacterType? _currentCharacter;
  ConfidenceScenario? _currentScenario;
  UserAdaptiveProfile? _userProfile;
  
  // Prompts syst√®me par personnage
  static const Map<AICharacterType, String> _characterSystemPrompts = {
    AICharacterType.thomas: '''Tu es Thomas, un manager exp√©riment√© et exigeant. Tu es professionnel, direct et analytique.
Tu coaches l'utilisateur pour am√©liorer sa communication professionnelle.
Caract√©ristiques:
- Ton direct et professionnel
- Focus sur la structure et la logique
- Exigeant mais constructif
- Donne des conseils pratiques et actionnables
R√©ponds toujours en fran√ßais et adapte ton niveau d'exigence selon la performance de l'utilisateur.''',
    
    AICharacterType.marie: '''Tu es Marie, une experte en relation client empathique et encourageante. Tu es intuitive et collaborative.
Tu aides l'utilisateur √† d√©velopper sa confiance en communication.
Caract√©ristiques:
- Ton empathique et bienveillant
- Focus sur l'√©motion et la relation
- Encourageante et positive
- Valorise les progr√®s m√™me petits
R√©ponds toujours en fran√ßais et adapte ton soutien selon le niveau de confiance de l'utilisateur.''',
  };

  // Prompts par type de sc√©nario
  static const Map<ConfidenceScenarioType, String> _scenarioContextPrompts = {
    ConfidenceScenarioType.interview: '''Context: L'utilisateur s'entra√Æne pour un entretien d'embauche.
Focus sur: clart√© des r√©ponses, structure STAR, exemples concrets, gestion du stress.''',
    
    ConfidenceScenarioType.presentation: '''Context: L'utilisateur pr√©pare une pr√©sentation professionnelle.
Focus sur: structure du discours, captation de l'attention, gestion du trac, contact visuel.''',
    
    ConfidenceScenarioType.meeting: '''Context: L'utilisateur participe √† une r√©union d'√©quipe.
Focus sur: prise de parole opportune, argumentation, √©coute active, synth√®se.''',
    
    ConfidenceScenarioType.networking: '''Context: L'utilisateur fait du networking professionnel.
Focus sur: pitch personnel, questions ouvertes, √©coute, cr√©ation de lien.''',
    
    ConfidenceScenarioType.pitch: '''Context: L'utilisateur pr√©sente un pitch commercial.
Focus sur: accroche, proposition de valeur, storytelling, call-to-action.''',
  };

  /// Initialise le moteur de conversation
  Future<void> initialize({
    required ConfidenceScenario scenario,
    required UserAdaptiveProfile userProfile,
    AICharacterType? preferredCharacter,
  }) async {
    _logger.i('üöÄ [$_tag] Initialisation pour ${scenario.title}');
    
    _currentScenario = scenario;
    _userProfile = userProfile;
    _conversationHistory.clear();
    
    // S√©lection du personnage optimal
    _currentCharacter = preferredCharacter ?? 
                       _aiCharacterService.selectOptimalCharacter(
                         scenario: scenario,
                         profile: userProfile,
                         userPreference: preferredCharacter,
                       );
    
    await _aiCharacterService.initialize();
    
    _logger.i('‚úÖ [$_tag] Initialis√© avec ${_currentCharacter?.displayName}');
  }

  /// G√©n√®re la premi√®re r√©ponse d'introduction du personnage IA
  Future<ConversationResponse> generateIntroduction() async {
    if (_currentScenario == null || _currentCharacter == null || _userProfile == null) {
      throw StateError('ConversationEngine non initialis√©');
    }
    
    _logger.d('üé≠ [$_tag] G√©n√©ration introduction ${_currentCharacter!.displayName}');
    
    // G√©n√©rer un dialogue d'introduction adaptatif
    final adaptiveDialogue = await _aiCharacterService.generateContextualDialogue(
      character: _currentCharacter!,
      phase: AIInterventionPhase.scenarioIntroduction,
      context: SessionContext(
        scenario: _currentScenario!,
        userProfile: _userProfile!,
        currentPhase: AIInterventionPhase.scenarioIntroduction,
        sessionDuration: Duration.zero,
        attemptsCount: 0,
        previousFeedback: [],
        currentMetrics: {},
      ),
    );
    
    // Cr√©er le contexte pour Mistral
    final systemPrompt = _buildSystemPrompt();
    final userPrompt = _buildIntroductionPrompt();
    
    // Appeler Mistral pour une r√©ponse plus naturelle
    final mistralResponse = await _callMistralAPI(
      '$systemPrompt\n\n$userPrompt'
    );
    
    // Cr√©er le tour de conversation
    final turn = ConversationTurn(
      speaker: ConversationSpeaker.ai,
      character: _currentCharacter!,
      message: mistralResponse,
      emotionalState: adaptiveDialogue.emotionalState,
      timestamp: DateTime.now(),
      metadata: {
        'phase': AIInterventionPhase.scenarioIntroduction.name,
        'scenario': _currentScenario!.id,
      },
    );
    
    _conversationHistory.add(turn);
    
    return ConversationResponse(
      message: mistralResponse,
      character: _currentCharacter!,
      emotionalState: adaptiveDialogue.emotionalState,
      suggestedUserResponses: _generateSuggestedResponses(turn),
      requiresUserResponse: true,
    );
  }

  /// G√©n√®re une r√©ponse IA bas√©e sur l'entr√©e utilisateur
  Future<String> generateResponse({
    required String userInput,
    required List<ConversationTurn> conversationHistory,
    required ConfidenceScenario scenario,
    required AICharacterType character,
    required UserAdaptiveProfile userProfile,
  }) async {
    _logger.i('üß† [MISTRAL] Generating response for $character');
    
    try {
      // 1. CONSTRUCTION DU PROMPT CONTEXTUEL
      final prompt = _buildContextualPrompt(
        userInput: userInput,
        conversationHistory: conversationHistory,
        scenario: scenario,
        character: character,
        userProfile: userProfile,
      );
      
      // 2. APPEL √Ä MISTRAL
      final response = await _callMistralAPI(prompt);
      
      // 3. POST-TRAITEMENT DE LA R√âPONSE
      final processedResponse = _postProcessResponse(response, character);
      
      _logger.i('‚úÖ [MISTRAL] Generated response: ${processedResponse.substring(0, math.min(100, processedResponse.length))}...');
      
      return processedResponse;
      
    } catch (e) {
      _logger.e('‚ùå [MISTRAL] Failed to generate response: $e');
      return _generateFallbackResponse(character, userInput);
    }
  }

  String _buildContextualPrompt({
    required String userInput,
    required List<ConversationTurn> conversationHistory,
    required ConfidenceScenario scenario,
    required AICharacterType character,
    required UserAdaptiveProfile userProfile,
  }) {
    final systemPrompt = _characterSystemPrompts[character]!;
    final scenarioContext = _scenarioContextPrompts[scenario.type]!;
    
    // Historique de conversation format√©
    final historyText = conversationHistory
        .reversed
        .take(6)
        .toList()
        .reversed
        .map((turn) => '${turn.speaker.name}: ${turn.message}')
        .join('\n');
    
    // Adaptation selon le profil utilisateur
    final adaptationNote = _buildAdaptationNote(userProfile);
    
    return '''
$systemPrompt

$scenarioContext

$adaptationNote

Historique de la conversation:
$historyText

Utilisateur: $userInput

R√©ponds en tant que ${character.name} de mani√®re naturelle et contextuelle. Ta r√©ponse doit:
1. √ätre coh√©rente avec ta personnalit√©
2. S'adapter au niveau de l'utilisateur
3. Faire progresser la conversation
4. Rester dans le contexte du sc√©nario
5. √ätre concise (2-3 phrases maximum)

R√©ponse:''';
  }

  Future<String> _callMistralAPI(String prompt) async {
    final response = await _httpService.post(
      '$_mistralBaseUrl/chat/completions',
      headers: {
        'Authorization': 'Bearer $_mistralApiKey',
        'Content-Type': 'application/json',
      },
      body: jsonEncode({
        'model': _mistralModel,
        'messages': [
          {'role': 'user', 'content': prompt}
        ],
        'max_tokens': 150,
        'temperature': 0.7,
        'top_p': 0.9,
      }),
      timeout: const Duration(seconds: 10),
    );
    
    if (response.statusCode == 200) {
      final data = json.decode(response.body);
      return data['choices'][0]['message']['content'].trim();
    } else {
      throw Exception('Mistral API error: ${response.statusCode}');
    }
  }
  
  String _postProcessResponse(String response, AICharacterType character) {
    // Nettoie la r√©ponse
    String cleaned = response.trim();
    
    // Supprime les pr√©fixes ind√©sirables
    cleaned = cleaned.replaceAll(RegExp(r'^(Thomas|Marie):\s*'), '');
    cleaned = cleaned.replaceAll(RegExp(r'^R√©ponse:\s*'), '');
    
    // Assure une ponctuation correcte
    if (!cleaned.endsWith('.') && !cleaned.endsWith('!') && !cleaned.endsWith('?')) {
      cleaned += '.';
    }
    
    return cleaned;
  }

  /// Construit le prompt syst√®me complet
  String _buildSystemPrompt() {
    final characterPrompt = _characterSystemPrompts[_currentCharacter!] ?? '';
    final scenarioPrompt = _scenarioContextPrompts[_currentScenario!.type] ?? '';
    
    return '''$characterPrompt

$scenarioPrompt

Instructions suppl√©mentaires:
- Reste dans ton r√¥le de ${_currentCharacter!.displayName} en permanence
- Adapte ton niveau selon la confiance de l'utilisateur (niveau ${_userProfile!.confidenceLevel}/10)
- Sois concis mais pertinent (max 3-4 phrases par r√©ponse)
- Pose des questions pour faire progresser la conversation
- Donne des conseils pratiques et actionnables''';
  }

  /// Construit le prompt d'introduction
  String _buildIntroductionPrompt() {
    return '''L'utilisateur vient de s√©lectionner le sc√©nario "${_currentScenario!.title}".
Description du sc√©nario: ${_currentScenario!.description}

Pr√©sente-toi bri√®vement et explique comment tu vas l'aider dans cet exercice.
Mets l'utilisateur √† l'aise tout en montrant ton expertise.''';
  }


  /// G√©n√®re des suggestions de r√©ponses pour l'utilisateur
  List<String> _generateSuggestedResponses(ConversationTurn aiTurn) {
    // Bas√© sur la phase et le contexte
    final phase = AIInterventionPhase.values.firstWhere(
      (p) => p.name == aiTurn.metadata['phase'],
      orElse: () => AIInterventionPhase.preparationCoaching,
    );
    
    switch (phase) {
      case AIInterventionPhase.scenarioIntroduction:
        return [
          "Je suis pr√™t(e) √† commencer",
          "J'ai quelques questions sur le sc√©nario",
          "Je me sens un peu stress√©(e)",
        ];
      case AIInterventionPhase.preparationCoaching:
        return [
          "Peux-tu me donner un exemple ?",
          "Comment puis-je m'am√©liorer ?",
          "Je vais essayer cette approche",
        ];
      case AIInterventionPhase.realTimeGuidance:
        return [
          "J'ai compris, je continue",
          "C'est difficile pour moi",
          "Merci pour le conseil",
        ];
      default:
        return [
          "Que penses-tu de ma performance ?",
          "Sur quoi dois-je me concentrer ?",
          "J'aimerais r√©essayer",
        ];
    }
  }

  String _buildAdaptationNote(UserAdaptiveProfile userProfile) {
    // Cette m√©thode peut √™tre √©tendue pour des adaptations plus fines
    if (userProfile.confidenceLevel < 4) {
      return "Note: L'utilisateur est d√©butant et peu confiant. Sois particuli√®rement encourageant et simple dans tes explications.";
    } else if (userProfile.confidenceLevel > 7) {
      return "Note: L'utilisateur est avanc√© et confiant. Challenge-le avec des questions plus complexes et des feedbacks plus directs.";
    }
    return "Note: L'utilisateur a un niveau interm√©diaire. Maintiens un √©quilibre entre soutien et challenge.";
  }

  /// R√©ponse de fallback en cas d'erreur Mistral
  String _generateFallbackResponse(AICharacterType character, String userInput) {
    _logger.w('Generating fallback response for $character');
    switch (character) {
      case AICharacterType.thomas:
        return "Je n'ai pas bien saisi votre point. Pouvez-vous reformuler votre id√©e plus clairement ?";
      case AICharacterType.marie:
        return "Excusez-moi, j'ai eu un petit probl√®me technique. Pouvez-vous r√©p√©ter ce que vous venez de dire ?";
    }
  }

  /// Obtient l'historique de conversation
  List<ConversationTurn> getConversationHistory() => List.unmodifiable(_conversationHistory);

  /// R√©initialise la conversation
  void reset() {
    _conversationHistory.clear();
    _currentCharacter = null;
    _currentScenario = null;
    _userProfile = null;
    _logger.i('üîÑ [$_tag] Conversation r√©initialis√©e');
  }
}

/// Mod√®le pour un tour de conversation
class ConversationTurn {
  final ConversationSpeaker speaker;
  final AICharacterType? character; // Null pour l'utilisateur
  final String message;
  final AIEmotionalState? emotionalState; // Null pour l'utilisateur
  final DateTime timestamp;
  final Map<String, dynamic> metadata;

  ConversationTurn({
    required this.speaker,
    required this.character,
    required this.message,
    required this.emotionalState,
    required this.timestamp,
    required this.metadata,
  });
}

/// Type de locuteur
enum ConversationSpeaker { user, ai }

/// Mod√®le de r√©ponse de conversation
class ConversationResponse {
  final String message;
  final AICharacterType character;
  final AIEmotionalState emotionalState;
  final List<String> suggestedUserResponses;
  final bool requiresUserResponse;

  ConversationResponse({
    required this.message,
    required this.character,
    required this.emotionalState,
    required this.suggestedUserResponses,
    required this.requiresUserResponse,
  });
}