# üéØ ARCHITECTURE LIVEKIT UNIVERSELLE - Eloquence

**Date :** 23 janvier 2025  
**Objectif :** Architecture audio universelle bas√©e sur LiveKit pour tous les exercices  
**Priorit√© :** Facilit√© d'impl√©mentation pour nouveaux exercices  

---

## üèóÔ∏è ARCHITECTURE CIBLE

### üì± Architecture Simplifi√©e LiveKit

```
üì± Flutter App
    ‚Üì UniversalLiveKitAudioService
üåê LiveKit Server (localhost:7880) 
    ‚îú‚îÄ‚îÄ Room Management ‚úÖ
    ‚îú‚îÄ‚îÄ Audio Streaming ‚úÖ
    ‚îú‚îÄ‚îÄ Real-time Transcription ‚úÖ
    ‚îî‚îÄ‚îÄ AI Agent Integration ‚úÖ
        ‚Üì
ü§ñ AI Backend (localhost:8003)
    ‚îú‚îÄ‚îÄ Vosk STT ‚úÖ
    ‚îú‚îÄ‚îÄ Mistral LLM ‚úÖ
    ‚îî‚îÄ‚îÄ Exercise Logic ‚úÖ
```

### üéØ PRINCIPE : "1 Service, Tous les Exercices"

**Service Universel :** `UniversalLiveKitAudioService`
- ‚úÖ **Connexion automatique** √† LiveKit
- ‚úÖ **Streaming audio** bidirectionnel
- ‚úÖ **Transcription temps r√©el**
- ‚úÖ **Gestion des erreurs** robuste
- ‚úÖ **Interface simple** pour nouveaux exercices

---

## üîß IMPL√âMENTATION SERVICE UNIVERSEL

### 1. Service Audio Universel Flutter

**Fichier :** `lib/core/services/universal_livekit_audio_service.dart`

```dart
import 'package:livekit_client/livekit_client.dart';
import 'package:flutter_riverpod/flutter_riverpod.dart';

class UniversalLiveKitAudioService {
  Room? _room;
  LocalAudioTrack? _audioTrack;
  bool _isConnected = false;
  
  // Callbacks pour les exercices
  Function(String)? onTranscriptionReceived;
  Function(String)? onAIResponseReceived;
  Function(Map<String, dynamic>)? onMetricsReceived;
  Function(String)? onErrorOccurred;

  /// Connexion universelle √† LiveKit
  Future<bool> connectToExercise({
    required String exerciseType,
    required String userId,
    Map<String, dynamic>? exerciseConfig,
  }) async {
    try {
      // 1. Obtenir token LiveKit
      final token = await _getLiveKitToken(exerciseType, userId);
      
      // 2. Cr√©er room
      _room = Room();
      
      // 3. Configurer listeners
      _setupRoomListeners();
      
      // 4. Se connecter
      await _room!.connect(
        'ws://localhost:7880',
        token,
        roomOptions: const RoomOptions(
          adaptiveStream: true,
          dynacast: true,
        ),
      );
      
      // 5. Publier audio
      await _publishAudio();
      
      _isConnected = true;
      return true;
      
    } catch (e) {
      onErrorOccurred?.call('Erreur connexion LiveKit: $e');
      return false;
    }
  }

  /// Publication audio automatique
  Future<void> _publishAudio() async {
    _audioTrack = await LocalAudioTrack.create(AudioCaptureOptions(
      sampleRate: 16000,
      channelCount: 1,
    ));
    
    await _room!.localParticipant!.publishAudioTrack(_audioTrack!);
  }

  /// Configuration des listeners universels
  void _setupRoomListeners() {
    _room!.addListener(() {
      // Gestion des √©v√©nements room
    });

    // Listener pour transcription
    _room!.on<DataReceivedEvent>((event) {
      final data = String.fromCharCodes(event.data);
      final message = jsonDecode(data);
      
      switch (message['type']) {
        case 'transcription':
          onTranscriptionReceived?.call(message['text']);
          break;
        case 'ai_response':
          onAIResponseReceived?.call(message['response']);
          break;
        case 'metrics':
          onMetricsReceived?.call(message['data']);
          break;
      }
    });
  }

  /// D√©connexion propre
  Future<void> disconnect() async {
    await _audioTrack?.stop();
    await _room?.disconnect();
    _isConnected = false;
  }

  /// Obtenir token LiveKit
  Future<String> _getLiveKitToken(String exerciseType, String userId) async {
    final response = await http.post(
      Uri.parse('http://localhost:8003/api/livekit/token'),
      headers: {'Content-Type': 'application/json'},
      body: jsonEncode({
        'exercise_type': exerciseType,
        'user_id': userId,
      }),
    );
    
    return jsonDecode(response.body)['token'];
  }
}

/// Provider Riverpod
final universalLiveKitServiceProvider = Provider<UniversalLiveKitAudioService>(
  (ref) => UniversalLiveKitAudioService(),
);
```

### 2. Mixin pour Exercices

**Fichier :** `lib/core/mixins/livekit_exercise_mixin.dart`

```dart
mixin LiveKitExerciseMixin<T extends ConsumerStatefulWidget> on ConsumerState<T> {
  UniversalLiveKitAudioService? _audioService;
  bool _isAudioActive = false;

  /// Initialisation audio pour l'exercice
  Future<void> initializeAudio({
    required String exerciseType,
    Map<String, dynamic>? config,
  }) async {
    _audioService = ref.read(universalLiveKitServiceProvider);
    
    // Configuration des callbacks
    _audioService!.onTranscriptionReceived = onTranscriptionReceived;
    _audioService!.onAIResponseReceived = onAIResponseReceived;
    _audioService!.onMetricsReceived = onMetricsReceived;
    _audioService!.onErrorOccurred = onAudioError;
    
    // Connexion
    final success = await _audioService!.connectToExercise(
      exerciseType: exerciseType,
      userId: 'user_123', // √Ä r√©cup√©rer du contexte
      exerciseConfig: config,
    );
    
    if (success) {
      setState(() {
        _isAudioActive = true;
      });
    }
  }

  /// Nettoyage audio
  Future<void> cleanupAudio() async {
    await _audioService?.disconnect();
    setState(() {
      _isAudioActive = false;
    });
  }

  // M√©thodes √† impl√©menter dans l'exercice
  void onTranscriptionReceived(String text);
  void onAIResponseReceived(String response);
  void onMetricsReceived(Map<String, dynamic> metrics);
  void onAudioError(String error);

  // Getters utiles
  bool get isAudioActive => _isAudioActive;
  UniversalLiveKitAudioService? get audioService => _audioService;
}
```

---

## üöÄ UTILISATION POUR NOUVEAUX EXERCICES

### Template d'Exercice Universel

**Fichier :** `lib/features/[exercise_name]/screens/[exercise_name]_screen.dart`

```dart
class NewExerciseScreen extends ConsumerStatefulWidget {
  @override
  _NewExerciseScreenState createState() => _NewExerciseScreenState();
}

class _NewExerciseScreenState extends ConsumerState<NewExerciseScreen>
    with LiveKitExerciseMixin {

  @override
  void initState() {
    super.initState();
    // Initialisation audio automatique
    WidgetsBinding.instance.addPostFrameCallback((_) {
      initializeAudio(
        exerciseType: 'new_exercise', // ‚Üê Nom de l'exercice
        config: {
          'difficulty': 'intermediate',
          'language': 'fr',
          // Configuration sp√©cifique √† l'exercice
        },
      );
    });
  }

  @override
  void dispose() {
    cleanupAudio(); // ‚Üê Nettoyage automatique
    super.dispose();
  }

  // ‚úÖ IMPL√âMENTATION SIMPLE - 4 m√©thodes seulement
  @override
  void onTranscriptionReceived(String text) {
    setState(() {
      // Traiter la transcription
      print('Transcription: $text');
    });
  }

  @override
  void onAIResponseReceived(String response) {
    setState(() {
      // Traiter la r√©ponse IA
      print('IA: $response');
    });
  }

  @override
  void onMetricsReceived(Map<String, dynamic> metrics) {
    setState(() {
      // Traiter les m√©triques
      print('M√©triques: $metrics');
    });
  }

  @override
  void onAudioError(String error) {
    ScaffoldMessenger.of(context).showSnackBar(
      SnackBar(content: Text('Erreur audio: $error')),
    );
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(title: Text('Nouvel Exercice')),
      body: Column(
        children: [
          // Indicateur de connexion audio
          if (isAudioActive)
            Container(
              padding: EdgeInsets.all(8),
              color: Colors.green,
              child: Text('üé§ Audio actif'),
            ),
          
          // Interface de l'exercice
          Expanded(
            child: Center(
              child: Text('Interface de l\'exercice'),
            ),
          ),
        ],
      ),
    );
  }
}
```

---

## üîß CONFIGURATION BACKEND LIVEKIT

### Agent LiveKit Universel

**Fichier :** `services/livekit-agent/universal_exercise_agent.py`

```python
import asyncio
from livekit import rtc
from livekit.agents import AutoSubscribe, JobContext, WorkerOptions, cli, llm
from livekit.agents.voice_assistant import VoiceAssistant
from livekit.plugins import openai, silero

class UniversalExerciseAgent:
    def __init__(self):
        self.exercise_handlers = {
            'confidence_boost': self.handle_confidence_boost,
            'presentation_skills': self.handle_presentation_skills,
            'interview_prep': self.handle_interview_prep,
            # Ajouter nouveaux exercices ici
        }

    async def entrypoint(self, ctx: JobContext):
        # Connexion √† la room
        await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)
        
        # R√©cup√©rer type d'exercice depuis metadata
        exercise_type = ctx.room.metadata.get('exercise_type', 'default')
        
        # D√©l√©guer au handler sp√©cifique
        handler = self.exercise_handlers.get(exercise_type, self.handle_default)
        await handler(ctx)

    async def handle_confidence_boost(self, ctx: JobContext):
        # Logique sp√©cifique Boost Confidence
        assistant = VoiceAssistant(
            vad=silero.VAD.load(),
            stt=openai.STT(),
            llm=openai.LLM(model="gpt-4"),
            tts=openai.TTS(),
        )
        
        assistant.start(ctx.room)
        await asyncio.sleep(1)
        
        # Prompt sp√©cifique
        await assistant.say(
            "Bonjour ! Je suis Marie, votre coach en confiance. "
            "Pr√©sentez-vous et parlez-moi de vos objectifs.",
            allow_interruptions=True
        )

    async def handle_presentation_skills(self, ctx: JobContext):
        # Logique sp√©cifique Pr√©sentation
        # ... impl√©mentation similaire
        pass

    async def handle_default(self, ctx: JobContext):
        # Handler par d√©faut pour nouveaux exercices
        assistant = VoiceAssistant(
            vad=silero.VAD.load(),
            stt=openai.STT(),
            llm=openai.LLM(model="gpt-4"),
            tts=openai.TTS(),
        )
        
        assistant.start(ctx.room)
        await assistant.say("Exercice d√©marr√©. Comment puis-je vous aider ?")

if __name__ == "__main__":
    cli.run_app(
        WorkerOptions(entrypoint_fnc=UniversalExerciseAgent().entrypoint)
    )
```

---

## üìã GUIDE CR√âATION NOUVEL EXERCICE

### √âtapes pour Ajouter un Exercice (5 minutes)

#### 1. **Cr√©er l'√©cran Flutter**
```bash
# Copier le template
cp lib/features/_template/exercise_template_screen.dart \
   lib/features/mon_exercice/screens/mon_exercice_screen.dart
```

#### 2. **Configurer l'exercice**
```dart
// Dans initializeAudio()
initializeAudio(
  exerciseType: 'mon_exercice', // ‚Üê Nom unique
  config: {
    'difficulty': 'beginner',
    'duration_minutes': 10,
    // Configuration sp√©cifique
  },
);
```

#### 3. **Ajouter le handler backend**
```python
# Dans universal_exercise_agent.py
async def handle_mon_exercice(self, ctx: JobContext):
    assistant = VoiceAssistant(...)
    await assistant.say("Message d'accueil sp√©cifique")
    # Logique sp√©cifique √† l'exercice

# Ajouter dans exercise_handlers
'mon_exercice': self.handle_mon_exercice,
```

#### 4. **Tester**
```bash
# D√©marrer LiveKit
docker-compose up livekit-server

# D√©marrer l'agent
python services/livekit-agent/universal_exercise_agent.py

# Tester Flutter
flutter run
```

---

## üéØ AVANTAGES ARCHITECTURE LIVEKIT

### ‚úÖ Pour les D√©veloppeurs

1. **Simplicit√© :** 4 m√©thodes √† impl√©menter par exercice
2. **R√©utilisabilit√© :** Service audio universel
3. **Robustesse :** Gestion d'erreurs centralis√©e
4. **Performance :** Streaming temps r√©el natif
5. **√âvolutivit√© :** Ajout d'exercices en 5 minutes

### ‚úÖ Pour les Utilisateurs

1. **Latence minimale :** Audio temps r√©el
2. **Qualit√© audio :** Codec optimis√© LiveKit
3. **Fiabilit√© :** Reconnexion automatique
4. **Exp√©rience fluide :** Interface unifi√©e

### ‚úÖ Pour la Maintenance

1. **Code centralis√© :** Un service pour tous
2. **Tests simplifi√©s :** Mocking du service universel
3. **Debugging facile :** Logs centralis√©s
4. **Monitoring :** M√©triques LiveKit int√©gr√©es

---

## üìä MIGRATION BOOST CONFIDENCE

### √âtapes de Migration

#### 1. **Remplacer flutter_sound par LiveKit**
```dart
// ‚ùå ANCIEN (flutter_sound)
FlutterSoundRecorder? _audioRecorder;
await _audioRecorder?.startRecorder();

// ‚úÖ NOUVEAU (LiveKit)
class ConfidenceBoostScreen extends ConsumerStatefulWidget
    with LiveKitExerciseMixin {
  // Impl√©mentation automatique
}
```

#### 2. **Simplifier l'initialisation**
```dart
// ‚ùå ANCIEN (complexe)
Future<void> _openAudioSession() async {
  await _audioRecorder?.openRecorder();
  // + 50 lignes de configuration
}

// ‚úÖ NOUVEAU (simple)
@override
void initState() {
  super.initState();
  initializeAudio(exerciseType: 'confidence_boost');
}
```

#### 3. **Callbacks automatiques**
```dart
// ‚úÖ NOUVEAU - Callbacks automatiques
@override
void onTranscriptionReceived(String text) {
  // Traitement transcription
}

@override
void onAIResponseReceived(String response) {
  // Traitement r√©ponse IA
}
```

---

## üöÄ PLAN D'IMPL√âMENTATION

### Phase 1 : Service Universel (2h)
1. ‚úÖ Cr√©er `UniversalLiveKitAudioService`
2. ‚úÖ Cr√©er `LiveKitExerciseMixin`
3. ‚úÖ Cr√©er template d'exercice

### Phase 2 : Agent Backend (1h)
1. ‚úÖ Cr√©er `UniversalExerciseAgent`
2. ‚úÖ Configurer handlers par exercice
3. ‚úÖ Tester connexion LiveKit

### Phase 3 : Migration Boost Confidence (1h)
1. ‚úÖ Migrer vers le nouveau service
2. ‚úÖ Tester fonctionnalit√© compl√®te
3. ‚úÖ Valider performance

### Phase 4 : Documentation (30min)
1. ‚úÖ Guide d√©veloppeur
2. ‚úÖ Exemples d'impl√©mentation
3. ‚úÖ Troubleshooting

---

## üìã R√âSULTAT FINAL

### ‚úÖ Architecture Cible Atteinte

```
üì± Flutter (Mixin LiveKit)
    ‚Üì 1 ligne d'initialisation
üåê LiveKit Server
    ‚Üì Streaming temps r√©el
ü§ñ Agent Universel
    ‚Üì Handler par exercice
üìä R√©sultats & M√©triques
```

### üéØ Objectifs Atteints

1. **‚úÖ Facilit√© d'impl√©mentation :** 5 minutes par exercice
2. **‚úÖ Architecture unifi√©e :** LiveKit pour tout
3. **‚úÖ Code r√©utilisable :** Service universel
4. **‚úÖ Performance optimale :** Streaming natif
5. **‚úÖ Maintenance simplifi√©e :** Code centralis√©

**Temps total d'impl√©mentation :** 4.5 heures  
**Gain pour futurs exercices :** 95% de code en moins  
**Performance :** Latence < 100ms, qualit√© audio optimale
