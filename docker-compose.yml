services:
  redis:
    image: redis:7-alpine
    restart: on-failure:5
    ports:
    - 6379:6379
    networks:
    - eloquence-network
    healthcheck:
      test:
      - CMD
      - redis-cli
      - ping
      interval: 10s
      timeout: 5s
      retries: 3
    volumes:
    - redis-data:/data
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    tmpfs:
    - /tmp:noexec,nosuid,size=100m
  api-backend:
    build:
      context: ./services/api-backend
      dockerfile: Dockerfile
    image: eloquence/api-backend:latest
    restart: unless-stopped # Politique de redémarrage robuste
    ports:
    - 8000:8000
    env_file:
    - .env
    environment:
    - LIVEKIT_URL=ws://livekit:7880
    - LIVEKIT_API_KEY=${LIVEKIT_API_KEY}
    - LIVEKIT_API_SECRET=${LIVEKIT_API_SECRET}
    - WHISPER_STT_URL=${WHISPER_STT_URL}
    - OPENAI_TTS_URL=${OPENAI_TTS_URL}
    - PYTHONUNBUFFERED=1
    - PYTHONDONTWRITEBYTECODE=1
    - PYTHONHASHSEED=random
    networks:
    - eloquence-network
    healthcheck: # Ajout du healthcheck
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    depends_on:
      livekit:
        condition: service_healthy
      redis:
        condition: service_healthy
      whisper-stt:
        condition: service_healthy
      openai-tts:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '3.0'
        reservations:
          memory: 1G
          cpus: '1.0'
    tmpfs:
    - /tmp:noexec,nosuid,size=200m
    volumes:
    - ./vad_diagnostic.py:/app/vad_diagnostic.py:ro
    - api-cache:/app/.cache
    labels:
      audio.fixed: 'true'
      modified.date: '2025-06-23T22:12:01.900806'
  livekit:
    image: livekit/livekit-server:latest
    command: --config /livekit.yaml
    restart: unless-stopped
    ports:
    - "7880:7880"
    - "7881:7881"
    # - "50000-60000:50000-60000/udp" # Commenté pour compatibilité Windows
    volumes:
    - ./services/livekit/livekit.yaml:/livekit.yaml:ro
    - livekit-data:/data
    networks:
    - eloquence-network
    healthcheck:
      # Utilise netcat (nc) pour vérifier si le port TCP est ouvert. C'est plus fiable que de dépendre d'un endpoint /health.
      test: ["CMD", "nc", "-z", "localhost", "7880"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    tmpfs:
    - /tmp:noexec,nosuid,size=100m
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
  whisper-stt:
    image: eloquence/whisper-stt:latest
    restart: unless-stopped # Politique de redémarrage robuste
    ports:
    - 8001:8001
    networks:
    - eloquence-network
    volumes:
    - whisper-models-data:/root/.cache/faster_whisper
    - whisper-tmp:/tmp/whisper
    environment:
    - PYTHONUNBUFFERED=1
    - PYTHONDONTWRITEBYTECODE=1
    - OMP_NUM_THREADS=4
    - CUDA_VISIBLE_DEVICES=0
    - WHISPER_CACHE_DIR=/root/.cache/faster_whisper
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8001/health
      interval: 15s
      timeout: 10s
      retries: 3
      start_period: 120s
    deploy:
      resources:
        limits:
          memory: 16G
          cpus: '4.0'
        reservations:
          memory: 8G
          cpus: '2.0'
    tmpfs:
    - /tmp:noexec,nosuid,size=2g
    ulimits:
      memlock:
        soft: -1
        hard: -1
  openai-tts:
    image: eloquence/openai-tts:latest
    restart: unless-stopped # Politique de redémarrage robuste
    ports:
    - 5002:5002
    env_file:
    - .env
    environment:
    - OPENAI_API_KEY=${OPENAI_API_KEY}
    - PYTHONUNBUFFERED=1
    - PYTHONDONTWRITEBYTECODE=1
    - PYTHONHASHSEED=random
    networks:
    - eloquence-network
    volumes:
    - tts-cache:/app/.cache
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:5002/health
      interval: 15s
      timeout: 10s
      retries: 3
      start_period: 90s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'
    tmpfs:
    - /tmp:noexec,nosuid,size=100m
  whisper-realtime:
    build:
      context: ./services/whisper-realtime
      dockerfile: Dockerfile
    image: eloquence/whisper-realtime:latest
    restart: unless-stopped
    ports:
    - 8006:8006
    env_file:
    - .env
    environment:
    - PYTHONUNBUFFERED=1
    - PYTHONDONTWRITEBYTECODE=1
    - PYTHONHASHSEED=random
    - TRANSFORMERS_CACHE=/app/.cache
    - HF_HOME=/app/.cache/huggingface
    - TORCH_HOME=/app/.cache/torch
    - TOKENIZERS_PARALLELISM=false
    - OMP_NUM_THREADS=1
    - WHISPER_MODEL_ID=${WHISPER_MODEL_ID}
    - WHISPER_DEVICE=${WHISPER_DEVICE}
    - AUDIO_SAMPLE_RATE=${AUDIO_SAMPLE_RATE}
    - AUDIO_CHUNK_DURATION=${AUDIO_CHUNK_DURATION}
    - MAX_AUDIO_BUFFER_SIZE=${MAX_AUDIO_BUFFER_SIZE}
    - HOST=0.0.0.0
    - PORT=8006
    networks:
    - eloquence-network
    volumes:
    - whisper-realtime-cache:/app/.cache
    - whisper-realtime-logs:/app/logs
    - whisper-realtime-temp:/app/temp
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8006/health
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    depends_on:
      whisper-stt:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'
    tmpfs:
    - /tmp:noexec,nosuid,size=500m
    labels:
      service.type: 'whisper-realtime'
      service.version: '1.0.0'
      replacement.for: 'hybrid-speech-evaluation'
  eloquence-agent-v1:
    build:
      context: ./services/api-backend
      dockerfile: Dockerfile.agent.dev
    image: eloquence/agent-v1:latest
    command: python -u services/real_time_voice_agent_force_audio_fixed.py dev
    restart: unless-stopped # Changé de 'no' à unless-stopped
    ports:
    - 8080:8080
    env_file:
    - .env
    environment:
    - LIVEKIT_URL=ws://livekit:7880
    - LIVEKIT_API_KEY=${LIVEKIT_API_KEY}
    - LIVEKIT_API_SECRET=${LIVEKIT_API_SECRET}
    - WHISPER_STT_URL=${WHISPER_STT_URL}
    - OPENAI_TTS_URL=${OPENAI_TTS_URL}
    - MISTRAL_API_KEY=${MISTRAL_API_KEY}
    - MISTRAL_BASE_URL=${MISTRAL_BASE_URL}
    - MISTRAL_MODEL=${MISTRAL_MODEL}
    - OPENAI_API_KEY=${OPENAI_API_KEY}
    - LIVEKIT_LOG_LEVEL=info
    - LIVEKIT_AGENT_NAME=eloquence-coach-v1
    - PYTHONUNBUFFERED=1
    - PYTHONDONTWRITEBYTECODE=1
    - PYTHONHASHSEED=random
    - OMP_NUM_THREADS=2
    networks:
    - eloquence-network
    volumes:
    - agent-cache:/app/.cache
    - agent-models:/app/data/models
    depends_on:
      livekit:
        condition: service_healthy # Changé de service_started
      redis:
        condition: service_healthy # Changé de service_started
      whisper-stt:
        condition: service_healthy
      openai-tts:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'
    tmpfs:
    - /tmp:noexec,nosuid,size=500m
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
networks:
  eloquence-network:
    driver: bridge
volumes:
  livekit-data:
    driver: local
  redis-data:
    driver: local
  whisper-models-data:
    driver: local
  api-cache:
    driver: local
  tts-cache:
    driver: local
  agent-cache:
    driver: local
  agent-models:
    driver: local
  whisper-tmp:
    driver: local
  whisper-realtime-cache:
    driver: local
  whisper-realtime-logs:
    driver: local
  whisper-realtime-temp:
    driver: local
